[{"title":"Mybatis-Plus与Springboot版本冲突","url":"/2026/01/19/error/Mybatis-Plus%E4%B8%8ESpringboot%E7%89%88%E6%9C%AC%E5%86%B2%E7%AA%81/","content":"问题背景创建一个新项目后，引入了mybatis-plus,完成最基础的几个类，然后直接运行出现以下报错。\norg.springframework.beans.factory.BeanDefinitionStoreException: Invalid bean definition with name &#x27;userMapper&#x27; defined in file [D:\\Project\\demo\\target\\classes\\com\\example\\demo\\mapper\\UserMapper.class]: Invalid value type for attribute &#x27;factoryBeanObjectType&#x27;: java.lang.String        at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.getTypeForFactoryBean(AbstractAutowireCapableBeanFactory.java:864) ~[spring-beans-6.2.8.jar:6.2.8]        at org.springframework.beans.factory.support.AbstractBeanFactory.getType(AbstractBeanFactory.java:745) ~[spring-beans-6.2.8.jar:6.2.8]        at org.springframework.beans.factory.support.DefaultListableBeanFactory.findAnnotationOnBean(DefaultListableBeanFactory.java:817) ~[spring-beans-6.2.8.jar:6.2.8]        at org.springframework.boot.sql.init.dependency.AnnotationDependsOnDatabaseInitializationDetector.detect(AnnotationDependsOnDatabaseInitializationDetector.java:36) ~[spring-boot-3.4.7.jar:3.4.7]        at org.springframework.boot.sql.init.dependency.DatabaseInitializationDependencyConfigurer$DependsOnDatabaseInitializationPostProcessor.detectDependsOnInitializationBeanNames(DatabaseInitializationDependencyConfigurer.java:152) ~[spring-boot-3.4.7.jar:3.4.7]        at org.springframework.boot.sql.init.dependency.DatabaseInitializationDependencyConfigurer$DependsOnDatabaseInitializationPostProcessor.postProcessBeanFactory(DatabaseInitializationDependencyConfigurer.java:115) ~[spring-boot-3.4.7.jar:3.4.7]        at org.springframework.context.support.PostProcessorRegistrationDelegate.invokeBeanFactoryPostProcessors(PostProcessorRegistrationDelegate.java:363) ~[spring-context-6.2.8.jar:6.2.8]        at org.springframework.context.support.PostProcessorRegistrationDelegate.invokeBeanFactoryPostProcessors(PostProcessorRegistrationDelegate.java:197) ~[spring-context-6.2.8.jar:6.2.8]\n\n问题原因造成这种原因主要是因为在引入mybatisplus的时候的版本不对，我使用的springboot版本是3.4.7的，但是引入的mybatisplus的依赖版本只能适用于springboot2.x。\n解决方法在pom文件中修改mybatisplus的版本以适配当前springboot版本。下方是mybatis—plus和springboot对应的版本关系。\n\n\n\nSpring Boot\nJDK\n推荐 MyBatis-Plus\n说明\n\n\n\n3.2.x &#x2F; 3.1.x\n17+\n3.5.5+\nJakarta 命名空间\n\n\n3.0.x\n17\n3.5.3+\n初期版本\n\n\n2.7.x\n8 &#x2F; 11\n3.5.3.2 ~ 3.5.5\n⭐ 最稳定、最常用\n\n\n2.6.x\n8 &#x2F; 11\n3.5.2 ~ 3.5.4\n可用\n\n\n2.5.x\n8\n3.4.3.4 ~ 3.5.1\n偏老\n\n\n≤ 2.4.x\n8\n≤ 3.4.x\n不建议新项目\n\n\n","categories":["错误汇总"],"tags":["Java"]},{"title":"Seata配置传递失败","url":"/2026/01/19/error/Seata%E9%85%8D%E7%BD%AE%E4%BC%A0%E9%80%92%E5%A4%B1%E8%B4%A5/","content":"问题背景微服务中有两个模块，common和cart模块，此时我想要给cart模块做分布式事务，所以要引入seata，因为考虑到可能其他模块也会用到分布式事务，所以我将该依赖直接引入到common中，依赖如下。\n&lt;!--seata--&gt;&lt;dependency&gt;    &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt;    &lt;artifactId&gt;spring-cloud-starter-alibaba-seata&lt;/artifactId&gt;&lt;/dependency&gt;\n\n引入后启动cart服务，报了如下错误。\n11:13:19:906 ERROR 20948 --- [eoutChecker_1_1] i.s.c.r.netty.NettyClientChannelManager  : can not get cluster name in registry config &#x27;service.vgroupMapping.default_tx_group&#x27;, please make sure registry config correct\n\n问题原因报错分析该处报错表明 Seata 客户端 在尝试查找default_tx_group事务组对应的集群名称，但你的配置里使用的是 hmall事务组（根据之前的配置）。但是我比对了seata服务端和客户端的所有文件均没有问题，真正问题所在如下。\n原因分析1.配置未生效在 common 模块引入了 spring-cloud-starter-alibaba-seata，但未在cart-service中显式配置 Seata 的事务组名称，导致Seata 客户端 回退到默认值 default_tx_group。2.依赖传递问题common 模块的依赖虽然传递到了cart-service，但 Seata 的配置不会自动继承，需要在每个微服务中单独配置。\n解决方法对于seata配置来说，在哪个微服务中需要使用一定要在对应的微服务中引入，然后在对应的微服务中需要加上seata的配置信息。\n","categories":["错误汇总"],"tags":["Java"]},{"title":"@NotNull失效","url":"/2026/01/19/error/@NotNull%E5%A4%B1%E6%95%88/","content":"问题背景今天将一个老项目的JDK从8升级到17以后发现所有的校验全部失效了，属性如下。\nimport javax.validation.constraints.NotNull;@NotNull(message = &quot;authType不能为空&quot;)private Integer authType;\n\n问题分析查阅资料以后发现，根本原因是 Java EE（Java Enterprise Edition）整体从 Oracle 转移到了 Eclipse 基金会，并更名为 Jakarta EE。由于 Oracle 拥有 “Java” 商标，Eclipse 基金会不能继续使用 javax.* 包名。因此，从 Jakarta EE 9 开始（2020年发布），所有原 Java EE 的 API 从 javax.* 重命名为 jakarta.*。这种问题最容易出现在升级了JDK17以后。\n解决方法修改导包路径即可，其他的校验注解的路径也一样。\nimport jakarta.validation.constraints.NotNull;","categories":["错误汇总"],"tags":["Java"]},{"title":"IDEA中快捷注释键不自动缩进","url":"/2026/01/19/idea-config/IDEA%E4%B8%AD%E5%BF%AB%E6%8D%B7%E6%B3%A8%E9%87%8A%E9%94%AE%E4%B8%8D%E8%87%AA%E5%8A%A8%E7%BC%A9%E8%BF%9B/","content":"问题背景在使用ctrl + &#x2F;快速注释以后，注释会显示在最左侧，看起来非常不舒服如下图。\n解决步骤修改Java中的注释修改完成以后的结果如下\n修改XML中的注释\n其他语言的注释格式也是同样的修改方式，可以自行尝试修改。\n未解决问题每次我在空白行处进行快速注释的时候，目前IDEA会根据下一行的列数来自定判定注释的位置，效果如下。\n但实际上我想要的效果如下，目前还有没找到修改方法，如果有大佬知道怎样修改请不吝赐教。\n","categories":["IDEA配置"],"tags":["IDEA","配置"]},{"title":"前端接收大数字有误","url":"/2026/01/19/error/%E5%89%8D%E7%AB%AF%E6%8E%A5%E5%8F%97%E5%A4%A7%E6%95%B0%E5%AD%97%E6%9C%89%E8%AF%AF/","content":"问题背景后端返回给前端的json对象中的id:1985693289158844418。但是前端收到的结果是id:1985693289158844420。该id的类型是Long类型的。\n问题原因JavaScript 的 Number 类型是基于 IEEE 754 双精度浮点数（64 位）实现的，其安全整数范围是 -(2^53 - 1) 到 2^53 - 1（即 ±9007199254740991）。超出这个范围的整数无法被精确表示。\n解决方法因为我们不可以手动将id的类型从Long类型改成String类型，这样会导致大量代码需要修改。使用 @JsonFormat(shape = JsonFormat.Shape.STRING)（Jackson）如下所示，这样id返回给前端的时候就是以字符串的形式发送了。\n@JsonFormat(shape = JsonFormat.Shape.STRING)private Long id;","categories":["错误汇总"],"tags":["Java"]},{"title":"mapstruct映射失败","url":"/2026/01/19/error/mapstruct%E6%98%A0%E5%B0%84%E5%A4%B1%E8%B4%A5/","content":"问题背景目前有两个类分别为UserVO和User类他们都继承了BaseObject，我在使用mapStruct的时候发现，User中的属性都成功赋值到了UserVO中，但是User中的BaseObject中的属性没有赋值到UserVO的BaseObject中。\n问题原因检查很久发现是因为在User中，我使用了@Builder的原因，当mapStruct在创建实现类的时候发现User类中有@Builder注解默认情况下就会通过建造者模式来构建对象，这就导致了BaseObject中的属性没有被赋值。这个是@Builder的问题导致的。当然如果在User中如果没有使用@Builder的话，mapStruct在构建实现类的时候就会通过get和set的最传统的方式生成。\n解决方法一般情况下我们的代码中也会用到@Builder，所以给出解决方法如下。这个属性表示让该接口的实现类中在需要构建类的时候默认不使用建造者模式。\nbuilder = @org.mapstruct.Builder(disableBuilder = true)","categories":["错误汇总"],"tags":["Java"]},{"title":"IDEA中快速创建自定义注释","url":"/2026/01/19/idea-config/IDEA%E4%B8%AD%E5%BF%AB%E9%80%9F%E5%88%9B%E5%BB%BA%E8%87%AA%E5%AE%9A%E4%B9%89%E6%B3%A8%E9%87%8A/","content":"问题背景在创建实体类或者方法以后，想要快速给其添加注释，如果手动输入的话会很慢，此时需要一组快捷键能快速生成注释代码块。\n操作步骤配置基本信息首先，按照下图顺序来配置基本信息。\n配置模板的作用范围默认情况下，设置完上述操作后是不生效的，需要配置该模板的生效的语言范围，比如说想让改模板只在Java中生效，那么在下图中只勾选Java即可，如果想偷懒就直接选择Everywhere。\n配置函数表达式因为我们在设置模板的时候使用到模板变量$DATE$，我们需要配置该变量，目的是当我们通过快捷键打印出改段注释的时候可以直接获取当前的日期。配置方法如下。\n至此，改配置已经完成，下面贴出两个我的常用的模板。\n类注释，快捷键：mas/** * $description$ * * @author  EnyooXu * @date    $DATE$ */\n\n方法注释，快捷键：md/** * $description$ * * @param  $param$ * @return 响应结果 */","categories":["IDEA配置"],"tags":["IDEA","配置","注释"]},{"title":"Redis","url":"/2026/01/21/study/Redis/","content":"简介Redis（REmote DIctionary Server），是一个开源的、高性能的内存数据库&#x2F;缓存&#x2F;消息中间件。\n数据类型String简介在 Redis 的所有数据结构中，String（字符串） 是最基础、最底层，也是使用频率最高的一种。虽然它叫“String”，但它不仅能存储文本，还能存储整数、浮点数、甚至二进制数据（如图片或序列化后的对象）。\n常用命令\n\n\n命令\n功能\n示例\n说明\n\n\n\nSET key value [NX&#x2F;XX] [EX seconds] [PX milliseconds]\n设置 key 的值，可带条件或过期时间\nSET mykey &quot;Hello&quot; EX 10 NX\n将 mykey 设置为 &quot;Hello&quot;，10 秒后过期，仅当 key 不存在时设置；NX&#x3D;仅不存在时设置，XX&#x3D;仅存在时设置，EX&#x3D;秒过期，PX&#x3D;毫秒过期\n\n\nGET key\n获取 key 的值\nGET mykey\n获取 mykey 的值，返回 &quot;Hello&quot;\n\n\nGETSET key value\n设置新值并返回旧值\nGETSET mykey &quot;World&quot;\n将 mykey 的值改为 &quot;World&quot;，返回旧值 &quot;Hello&quot;\n\n\nMGET key1 key2 …\n获取多个 key 的值\nMGET mykey anotherkey\n返回多个 key 的值，例如 [&quot;World&quot;, &quot;value2&quot;]\n\n\nSETNX key value\n当 key 不存在时设置值\nSETNX mykey &quot;Hello&quot;\n仅当 mykey 不存在时才设置值，存在则不做修改，返回 1 成功，0 失败\n\n\nSETEX key seconds value\n设置值并指定过期时间（秒）\nSETEX mykey 10 &quot;Hello&quot;\n设置 mykey 为 &quot;Hello&quot; 并在 10 秒后过期\n\n\n应用\n缓存 (Caching)这是最普遍的用法。将复杂的数据库查询结果（通常序列化为 JSON 字符串）存入 Redis，并设置过期时间。\n\nSET user:1001 &#x27;&#123;&quot;name&quot;:&quot;张三&quot;, &quot;age&quot;:25&#125;&#x27; EX 3600\n\n\n计数器 (Counter)利用其原子性。例如：文章阅读量、微博转发数、视频点赞数。例如：有一个需求希望id能一直递增，例如1,2,3,4,5，当删除了id为5的数据后，希望下一次增加数据的id为6，这种情况下非常推荐使用该计数器。\n\nINCR post:view:45672\n\n\n分布式锁 (Distributed Lock)利用 SET … NX 特性。\n\nSET lock_order_123 &quot;process_id&quot; NX EX 10\n\n\n限速器 (Rate Limiter)例如限制某个 IP 每分钟只能访问 10 次，防止恶意刷接口。\n\n# 伪代码逻辑val = INCR ip:192.168.1.1IF val == 1 THEN EXPIRE ip:192.168.1.1 60IF val &gt; 10 THEN REJECT\n\nHash简介Hash（哈希） 是一个 String 类型的 Field（字段） 和 Value（值） 的映射表。 如果你熟悉编程语言，可以把它类比为 Python 的dict、Java的 HashMap 或者 PHP 的 Array。上文中String类型存的都是一个类型的数据，Hash可以理解为存的是一个JSON对象。redis可以直接操作这个JSON对象。\n常用命令\n\n\n命令\n功能\n示例\n说明\n\n\n\nHSET key field value\n设置哈希字段的值\nHSET user:1 name &quot;Alice&quot;\n将 user:1 的 name 字段设置为 &quot;Alice&quot;\n\n\nHGET key field\n获取哈希字段的值\nHGET user:1 name\n获取 user:1 的 name 字段值，返回 &quot;Alice&quot;\n\n\nHMSET key field1 value1 field2 value2 …\n设置多个哈希字段的值\nHMSET user:1 age 25 city &quot;New York&quot;\n同时设置多个字段，例如 age 为 25，city 为 &quot;New York&quot;\n\n\nHMGET key field1 field2 …\n获取多个哈希字段的值\nHMGET user:1 name age\n获取多个字段的值，返回 [&quot;Alice&quot;, &quot;25&quot;]\n\n\nHGETALL key\n获取哈希中所有字段和值\nHGETALL user:1\n获取整个哈希，返回 [&quot;name&quot;, &quot;Alice&quot;, &quot;age&quot;, &quot;25&quot;, &quot;city&quot;, &quot;New York&quot;]\n\n\nHDEL key field1 field2 …\n删除一个或多个哈希字段\nHDEL user:1 age city\n删除指定字段，例如 age 和 city\n\n\nHEXISTS key field\n判断哈希字段是否存在\nHEXISTS user:1 name\n如果字段存在返回 1，否则返回 0\n\n\nHKEYS key\n获取哈希中所有字段\nHKEYS user:1\n返回哈希中所有字段名，例如 [&quot;name&quot;]\n\n\nHVALS key\n获取哈希中所有值\nHVALS user:1\n返回哈希中所有字段值，例如 [&quot;Alice&quot;]\n\n\nHLEN key\n获取哈希字段数量\nHLEN user:1\n返回field数量\n\n\n应用\n存储对象数据如购物车信息（Key 为用户 ID，Field 为商品 ID，Value 为商品数量、用户信息、配置信息。\n聚合数据统计比如统计一篇文章的多个指标（阅读数、点赞数、收藏数），可以全部放在一个 Hash Key 下，方便统一管理。\n\n存储原理Hash数据类型的底层存储并不是一成不变的，而是会根据数据规模和配置在ziplist / listpack 和 hashtable两种编码之间自动切换，这是Redis 非常经典的一种“节省内存的设计”。\n\nziplist &#x2F; listpack：当Hash中的字段数量较少，每个 field 和 value 的长度较短时会使用该种结构，这种结构本质就是一块连续的内存，没有指针，非常节省内存。在Redis3.x ~ 5.x会使用 ziplist，在Redis 6.0+：改为 listpack（ziplist 的升级版）。\nhashtable：当Hash中字段大于512或者任一 field 或 value 长度 &gt; 64 字节时就会转成hashtable结构，他的底层是Redis 自己实现的dict，基于数组 + 链表的结构，查询速度基本为o(1)，但是同时有指针带来的开销，会增加内存的使用空间。\n\nList简介Redis 的 List 是一个“有序、可重复、两端高效操作”的链表结构，底层从 ziplist&#x2F;listpack 进化为quicklist。可以将它理解为Java中的Deque这种数据结构。\n常用命令\n\n\n命令\n功能\n示例\n说明\n\n\n\nLPUSH key value1 value2 …\n将一个或多个值插入列表头部\nLPUSH mylist a b c\n按顺序插入头部，最终列表为 [&quot;c&quot;,&quot;b&quot;,&quot;a&quot;]\n\n\nRPUSH key value1 value2 …\n将一个或多个值插入列表尾部\nRPUSH mylist a b c\n按顺序插入尾部，最终列表为 [&quot;a&quot;,&quot;b&quot;,&quot;c&quot;]\n\n\nLPOP key\n移除并获取列表的第一个元素\nLPOP mylist\n移除并返回列表头部的元素\n\n\nRPOP key\n移除并获取列表的最后一个元素\nRPOP mylist\n移除并返回列表尾部的元素\n\n\nLLEN key\n获取列表长度\nLLEN mylist\n返回列表中元素的数量\n\n\nLRANGE key start end\n获取列表中指定范围的元素\nLRANGE mylist 0 -1\n获取整个列表，返回 [&quot;c&quot;,&quot;b&quot;,&quot;a&quot;]\n\n\nLLEN key\n获取列表的长度\nLLEN mylist\n返回 3（列表中元素个数）\n\n\nLINDEX key index\n根据下标获取列表中的元素\nLINDEX mylist 1\n返回 &quot;b&quot;（索引从 0 开始）\n\n\nLSET key index value\n修改列表指定下标位置的值\nLSET mylist 1 &quot;x&quot;\n将索引 1 的元素修改为 &quot;x&quot;，列表变为 [&quot;c&quot;,&quot;x&quot;,&quot;a&quot;]\n\n\nLTRIM key start end\n按指定区间裁剪列表\nLTRIM mylist 0 1\n只保留索引 0 和 1 的元素，列表变为 [&quot;c&quot;,&quot;x&quot;]\n\n\n应用\n消息队列 &#x2F; 任务队列生产者将任务LPUSH到列表头部，消费者用RPOP或BRPOP弹出执行。一般在异步任务处理、日志收集、消息通知等方面可以使用。\n\nLPUSH task_queue &quot;task1&quot;LPUSH task_queue &quot;task2&quot;RPOP task_queue\n\n\n最近访问 &#x2F; 历史记录使用列表头部插入新元素，限制长度 LTRIM。适用于浏览历史、聊天记录、操作日志。只保留最新的 N 条数据。\n\nLPUSH user:123:recent_views &quot;item42&quot;LTRIM user:123:recent_views 0 9  # 只保留最近10条LRANGE user:123:recent_views 0 -1\n\nSet简介Set 是一种 无序、不重复元素集合，可以把它想象成数学中的集合，操作元素很高效，并且可以快速做集合运算。\n常用命令\n\n\n命令\n功能说明\n示例\n效果说明\n\n\n\nSADD key member [member …]\n添加一个或多个元素到集合\nSADD myset a b c\n集合 myset 中增加元素 a、b、c，重复元素会被忽略\n\n\nSREM key member [member …]\n从集合中删除一个或多个元素\nSREM myset b\n删除集合 myset 中的元素 b\n\n\nSISMEMBER key member\n判断元素是否在集合中\nSISMEMBER myset a\n返回 1 表示元素 a 存在，0 表示不存在\n\n\nSCARD key\n获取集合元素数量\nSCARD myset\n返回集合 myset 的元素个数\n\n\nSMEMBERS key\n获取集合中的所有元素\nSMEMBERS myset\n返回集合 myset 的所有元素，如 [&quot;a&quot;,&quot;c&quot;]\n\n\nSRANDMEMBER key [count]\n随机返回一个或多个元素\nSRANDMEMBER myset 2\n随机返回集合中的 2 个元素，不删除\n\n\nSPOP key [count]\n随机弹出一个或多个元素\nSPOP myset 1\n随机弹出集合中 1 个元素，元素会被删除\n\n\nSMOVE source dest member\n将元素从一个集合移动到另一个集合\nSMOVE myset otherset a\n将元素 a 从 myset 移到 otherset\n\n\nSINTER key [key …]\n求多个集合的交集\nSINTER set1 set2\n返回集合 set1 和 set2 的公共元素\n\n\nSUNION key [key …]\n求多个集合的并集\nSUNION set1 set2\n返回集合 set1 和 set2 的所有元素去重\n\n\nSDIFF key [key …]\n求集合差集\nSDIFF set1 set2\n返回在 set1 但不在 set2 的元素\n\n\nSINTERSTORE dest key [key …]\n求交集并存入新集合\nSINTERSTORE newset set1 set2\n将 set1 与 set2 的交集存入 newset\n\n\nSUNIONSTORE dest key [key …]\n求并集并存入新集合\nSUNIONSTORE newset set1 set2\n将 set1 与 set2 的并集存入 newset\n\n\nSDIFFSTORE dest key [key …]\n求差集并存入新集合\nSDIFFSTORE newset set1 set2\n将 set1 与 set2 的差集存入 newset\n\n\n应用\n存储的值需要唯一因为set自动会进行去重，所以可以用来做存储唯一的用户 ID、IP、手机号等。\n\nSADD user_ids 123SADD user_ids 123  # 不会重复\n\n\n用来做社交关系比如说用set来存储用户关注，当需要查询共同好友，互粉等情况时，可以使用set来实现。\n\nSINTER user:alice:friends user:bob:friends\n\n\n抽奖的实现因为set是无序的，所以每次从set中抽出的值都是随机的，可以用来模拟抽奖。\n\nSRANDMEMBER prizes 3\n\n存储原理set底层是有两种数据结构的分别是intset和hashtable，底层小集合用 intset 压缩存储，大集合用哈希表，高效支持查找、添加、删除和集合运算，同时自动根据元素类型和数量切换存储策略。\n\n当集合元素全是整数且数量较少时会使用intset，他是一块连续的内存数组，占用内存较小，查询效率极高。\n当添加非整数或者元素数量超阈值（默认512），Redis 会自动转换为 Hash Table。底层使用dict（哈希表）存储，只使用哈希表的key，value通常默认都是为null来保证元素的唯一性，查找、添加、删除都非常快，但是他会占用更多的内存空间。\n\nZSet简介ZSet是一种 有序、唯一元素集合，其中每一个元素都有一个分数，并按照元素按照分数升序排序，分数可以相同，但是元素不可以重复。\n常用命令\n\n\n命令\n功能说明\n示例\n效果说明\n\n\n\n\n\nZADD key score member [score member …]\n添加一个或多个元素到有序集合，若元素存在则更新 score\nZADD myzset 1 a 2 b\n将元素 a（score&#x3D;1）和 b（score&#x3D;2）添加到 myzset，如果已存在则更新分数\n\n\n\n\nZREM key member [member …]\n从有序集合中删除一个或多个元素\nZREM myzset a\n删除 myzset 中的元素 a\n\n\n\n\nZSCORE key member\n获取元素的 score 值\nZSCORE myzset a\n返回元素 a 的 score 值，例如 1.0\n\n\n\n\nZRANK key member\n获取元素按 score 升序的排名\nZRANK myzset b\n返回元素 b 的排名（0 为最小 score），不存在返回 nil\n\n\n\n\nZREVRANK key member\n获取元素按 score 降序的排名\nZREVRANK myzset b\n返回元素 b 的降序排名\n\n\n\n\nZRANGE key start stop [WITHSCORES]\n按排名范围返回元素，可选返回 score\nZRANGE myzset 0 1 WITHSCORES\n返回排名第 0 和 1 的元素及 score，例如 [(&quot;a&quot;,1),(&quot;b&quot;,2)]\n\n\n\n\nZREVRANGE key start stop [WITHSCORES]\n按排名逆序返回元素，可选返回 score\nZREVRANGE myzset 0 1 WITHSCORES\n返回最高 score 前两个元素及 score\n\n\n\n\nZRANGEBYSCORE key min max [WITHSCORES]\n按 score 范围返回元素\nZRANGEBYSCORE myzset 1 2 WITHSCORES\n返回 score 在 1~2 范围的元素及 score\n\n\n\n\nZREVRANGEBYSCORE key max min [WITHSCORES]\n按 score 范围逆序返回元素\nZREVRANGEBYSCORE myzset 2 1 WITHSCORES\n返回 score 在 2~1 范围的元素及 score（降序）\n\n\n\n\nZCOUNT key min max\n统计 score 在指定范围的元素数量\nZCOUNT myzset 1 2\n返回 score 在 1~2 的元素数量\n\n\n\n\nZCARD key\n获取有序集合中元素数量\nZCARD myzset\n返回 myzset 中元素总数\n\n\n\n\nZINCRBY key increment member\n给元素的 score 增加指定值\nZINCRBY myzset 2 a\n元素 a 的 score 增加 2，如果不存在则添加 a 并设置 score&#x3D;2\n\n\n\n\nZPOPMIN key [count]\n弹出 score 最小的元素，可指定数量\nZPOPMIN myzset 1\n返回并删除 score 最小的元素\n\n\n\n\nZPOPMAX key [count]\n弹出 score 最大的元素，可指定数量\nZPOPMAX myzset 1\n返回并删除 score 最大的元素\n\n\n\n\nZREM RANGE BY RANK key start stop\n按排名范围删除元素\nZREMRANGEBYRANK myzset 0 1\n删除排名第 0 和 1 的元素\n\n\n\n\nZREM RANGE BY SCORE key min max\n按 score 范围删除元素\nZREMRANGEBYSCORE myzset 1 2\n删除 score 在 1~2 范围的元素\n\n\n\n\n应用\n排行榜 &#x2F; 积分榜可以拿key当做用户id，value来存储用户的游戏积分，并按照积分来进行排序。其他排行榜也是类似使用。\n带去重的延迟队列一般情况下使用list就可以完成延迟队列，但是如果需要实现去重就可以使用zset数据结构。\n\nGEO用于存储地理坐标（经度、纬度）并支持各种地理空间的计算如： 距离计算、 范围搜索、 最近点查询、 按距离排序；\n常用命令\n\n\n命令\n功能说明\n示例\n执行效果\n\n\n\nGEOADD key longitude latitude member [longitude latitude member ...]\n添加地理位置坐标到指定 key\nGEOADD locations 116.397128 39.916527 &quot;Beijing&quot;\n将 &quot;Beijing&quot; 的经纬度坐标加入 locations\n\n\nGEOPOS key member [member ...]\n获取一个或多个成员的经纬度\nGEOPOS locations &quot;Beijing&quot;\n返回 [116.397128, 39.916527]\n\n\nGEODIST key member1 member2 [unit]\n计算两个成员之间的距离\nGEODIST locations &quot;Beijing&quot; &quot;Shanghai&quot; km\n返回北京到上海的距离（单位 km）\n\n\nGEOHASH key member [member ...]\n返回成员的 geohash 值\nGEOHASH locations &quot;Beijing&quot;\n返回 &quot;wx4g0c0&quot; 形式的 geohash 编码\n\n\n应用\n附近的人 &#x2F; 商家 &#x2F; 车辆比如说打车软件中的“查找用户周围 1km内的出租车”等。注意着点和neo4j的功能不同，neo4j更加侧重于最优路径的计算。以物流运输成本为例：因为在一个实际运输项目中还有包含运费过路费等其他复杂情况，有时候不一定距离最短的情况下成本是最低的，neo4j更擅长这种计算。\n\n除了上述的这些数据结构以外，redis还有很多其他类型的数据结构，但是使用频率一般情况下来说不是很高，有需要可以再了解。\n通用指令\n\n\n命令\n功能说明\n示例\n效果说明\n\n\n\nDEL key [key …]\n删除一个或多个键\nDEL mykey\n删除键 mykey，如果不存在则忽略\n\n\nEXISTS key [key …]\n判断一个或多个键是否存在\nEXISTS mykey\n返回 1 表示存在，0 表示不存在\n\n\nEXPIRE key seconds\n设置键的过期时间（秒）\nEXPIRE mykey 60\nmykey 在 60 秒后自动删除\n\n\nPEXPIRE key milliseconds\n设置键的过期时间（毫秒）\nPEXPIRE mykey 1500\nmykey 在 1.5 秒后自动删除\n\n\nTTL key\n查看键的剩余生存时间（秒）\nTTL mykey\n返回 mykey 的剩余生存时间，-1 表示永久，-2 表示不存在\n\n\nPTTL key\n查看键的剩余生存时间（毫秒）\nPTTL mykey\n返回 mykey 的剩余毫秒数\n\n\nPERSIST key\n移除键的过期时间，使其永久存在\nPERSIST mykey\nmykey 成为永久键，不再过期\n\n\nRENAME key newkey\n重命名键\nRENAME mykey newkey\n将 mykey 重命名为 newkey，如果 newkey 存在会覆盖\n\n\nRENAMENX key newkey\n仅当 newkey 不存在时重命名\nRENAMENX mykey newkey\n返回 1 表示成功重命名，0 表示 newkey 已存在\n\n\nTYPE key\n查看键的数据类型\nTYPE mykey\n返回 mykey 的类型，如 string、list、set、zset、hash\n\n\nKEYS pattern\n查找符合模式的键\nKEYS user*\n返回所有以 user 开头的键（不推荐生产环境大量使用）\n\n\nSCAN cursor [MATCH pattern] [COUNT count]\n增量迭代扫描键\nSCAN 0 MATCH user* COUNT 10\n返回部分符合模式的键，支持分页迭代，安全生产使用\n\n\nTTL key\n获取键的剩余时间（秒）\nTTL mykey\n查看 mykey 剩余秒数，-1 表示永久，-2 表示不存在\n\n\nDUMP key\n序列化键的值为二进制字符串\nDUMP mykey\n返回 mykey 的序列化二进制，可以用于迁移或备份\n\n\nRESTORE key ttl serialized-value\n恢复序列化的键值\nRESTORE mykey 0 &quot;\\x00...&quot;\n将序列化数据恢复成键 mykey\n\n\nEXISTS key\n判断键是否存在\nEXISTS mykey\n返回 1 表示存在，0 表示不存在\n\n\nOBJECT subcommand key\n查看键的内部信息\nOBJECT REFCOUNT mykey\n查看键的引用计数、编码方式等（调试用）\n\n\nMOVE key db\n将键移动到指定数据库\nMOVE mykey 1\n将 mykey 移到 Redis 的 db1，如果目标 db 有同名键返回 0\n\n\nFLUSHDB\n删除当前数据库的所有键\nFLUSHDB\n当前数据库全部清空\n\n\nFLUSHALL\n删除所有数据库的所有键\nFLUSHALL\nRedis 实例中所有键全部清空\n\n\nPERSIST key\n移除键的过期时间\nPERSIST mykey\n使 mykey 永久存在\n\n\nRENAME key newkey\n重命名键\nRENAME mykey newkey\n将 mykey 改名为 newkey\n\n\nRedis问题缓存雪崩简介缓存雪崩（Cache Avalanche）是指在极短时间内，大量的缓存同时失效，或者 Redis 插件宕机，导致原本应该访问缓存的请求全部涌向数据库，造成数据库压力剧增甚至崩溃的现象。\n解决方法大量 Key 同时过期这是最常见的雪崩诱因，通常是因为批量写入数据时设置了相同的过期时间。\n\n设置随机过期时间： 在原有的过期时间基础上，加上一个随机值（例如 1-5 分钟的随机偏差）。这样可以分散 Key 的失效时间点，避免集体过期。\n设置热点数据永不过期： 对于一些极高频访问的业务数据，不设置过期时间，而是由后台逻辑在数据更新时主动去同步或更新缓存。\n逻辑过期： 在缓存的 Value 中包含一个“过期时间”字段。查询时发现逻辑时间已过期，则通过中间件或异步线程去更新缓存，而当前请求先返回旧数据，实现“准实时”且“高可用”。\n\nRedis 宕机&#x2F;不可用如果雪崩是因为 Redis 服务本身挂了，就需要在架构层面进行加固。\n\n构建 Redis 高可用集群： 使用 Redis Sentinel（哨兵模式） 或 Redis Cluster（集群模式）。当主节点宕机时，系统能自动进行故障转移，实现秒级切换。\n多级缓存架构： 使用 本地缓存（如 Guava Cache、Caffeine） + 远程分布式缓存（Redis）。 即使 Redis 挂了，本地缓存还能扛住一部分流量，为数据库争取缓冲时间。\n\n数据库层级的保护当缓存已经失效，流量已经冲向数据库时，就需要在数据库层最后一层防线。\n\n服务熔断与限流： 使用 Sentinel 或 Hystrix 等组件。一旦检测到数据库压力过大或响应变慢，直接启动熔断机制，暂停非核心业务的访问，并进行请求降级（返回默认值或错误页面），保护数据库不被冲垮。\n\n缓存击穿简介缓存击穿是指某一个极其热点的 Key 在过期的瞬间，有海量的并发请求同时涌入。由于缓存失效，这些请求会同时冲向数据库，可能导致数据库瞬间瘫痪。\n解决方法互斥锁(redis分布式锁)这是最常用的方案。当缓存失效时，不立即去查询数据库，而是先尝试获取一个互斥锁（如 Redis 的setnx），只有获得锁的那个线程能去查询数据库并回写缓存，其他线程则不断重试或等待。这样当获得锁的线程查询数据库以后会将值重新放到缓存中，并将锁释放。当其他线程发现获取锁后会第一时间再次查询redis中的数据，发现此时已经有数据了就直接返回，没有的话重复第一个线程的动作。这种方法通常用在订单，金融方面等对数据的准确性要求较高的地方使用。下面举一个使用Redisson实现分布式锁的例子。\nimport org.redisson.api.RLock;import org.redisson.api.RedissonClient;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.data.redis.core.StringRedisTemplate;import org.springframework.stereotype.Service;import java.util.concurrent.TimeUnit;@Servicepublic class CacheService &#123;    @Autowired    private StringRedisTemplate redisTemplate;    @Autowired    private RedissonClient redissonClient;    public String getData(String key) &#123;        // 1. 先从缓存中获取数据        String value = redisTemplate.opsForValue().get(key);        // 2. 缓存命中则直接返回        if (value != null) &#123;            return value;        &#125;        // 3. 缓存缺失，准备获取互斥锁        String lockKey = &quot;lock:&quot; + key;        RLock lock = redissonClient.getLock(lockKey);        try &#123;            /*             * tryLock 参数说明：             * waitTime:  等待锁的时间（10秒），超过则放弃             * leaseTime: 锁的自动释放时间（30秒），防止宕机死锁             */            if (lock.tryLock(10, 30, TimeUnit.SECONDS)) &#123;                try &#123;                    // 4. 【关键】获取锁后，再次检查缓存（Double Check）                    // 理由：高并发下，第一个线程写完缓存释放锁后，后续线程进锁时不应再查库                    value = redisTemplate.opsForValue().get(key);                    if (value != null) &#123;                        return value;                    &#125;                    // 5. 查询数据库                    value = queryDatabase(key);                    // 6. 回写缓存，并设置随机过期时间防止雪崩                    if (value != null) &#123;                        int expireTime = 30 + (int) (Math.random() * 10); // 30-40min                        redisTemplate.opsForValue().set(key, value, expireTime, TimeUnit.MINUTES);                    &#125;                &#125; finally &#123;                    // 7. 释放锁                    lock.unlock();                &#125;            &#125; else &#123;                // 8. 获取不到锁的线程，休眠后重试（或返回降级结果）                Thread.sleep(100);                return getData(key);            &#125;        &#125; catch (InterruptedException e) &#123;            Thread.currentThread().interrupt();            return null; // 或者抛出业务异常        &#125;        return value;    &#125;    private String queryDatabase(String key) &#123;        // 模拟数据库查询        return &quot;DataFromDB_for_&quot; + key;    &#125;&#125;\n\n逻辑过期这种方案不再给 Redis 的 Key 设置真实的过期时间（TTL），而是把过期时间存放在 Value 字段中。\n\n查询缓存，取出数据后判断其中的“逻辑过期时间”。\n如果已过期，开启一个异步线程去查询数据库并更新缓存。\n在异步更新完成前，当前请求（以及其他并发请求）直接返回旧数据。\n\n这种做法的性能极高，不存在线程阻塞等待，用户体验好，但是会存在数据不一致的情况（用户会拿到旧数据），且会增加代码的复杂度。\n其他方法\n热点数据预热： 在秒杀活动或高峰期开始前，提前将热点 Key 写入缓存，并手动延长其有效期。\n永久不过期： 对于流量极大的静态配置类数据，直接设置为永久有效，通过后台管理系统手动触发更新。\n\n\n缓存穿透简介缓存穿透指查询一个根本不存在的数据。由于缓存中没有（肯定没中），数据库中也没有（查询结果为空），导致每次请求都要去数据库查询。如果有攻击者伪造大量不存在的Key 进行恶意攻击，数据库会因承受不住压力而瘫痪。\n解决方法缓存空对象当数据库返回空结果时，我们也把这个“空值”（如 null 或特定的默认值）写入缓存，并设置一个较短的过期时间（例如 1-5分钟）。这种方法实现简单且维护方便，但是如果查询redis中的key是随机生成的会消耗Redis大量内存来存储这些空数据。通过可能会导致短期的数据不一致(如果之后数据库真的插入了这个 Key 的数据)。\n布隆过滤器在请求进入缓存层之前，先经过一层布隆过滤器。布隆过滤器由一个很长的二进制向量（位图）和一系列哈希函数组成。它能告诉你：“这个Key 可能存在”或“这个 Key 绝对不存在”。 如果布隆过滤器说不存在，直接拦截请求并返回。 如果布隆过滤器说可能存在，才去访问 Redis和数据库。布隆过滤器占用的内存很小而且能有效拦截大部分的非法请求，但是通过也是存在误判的可能。\n@Autowiredprivate RedissonClient redissonClient;public String getDataWithBloom(String key) &#123;    // 1. 获取布隆过滤器    RBloomFilter&lt;String&gt; bloomFilter = redissonClient.getBloomFilter(&quot;user_filter&quot;);    // 2. 如果布隆过滤器判断绝对不存在，直接拦截    if (!bloomFilter.contains(key)) &#123;        return null;    &#125;    // 3. 后续走正常的 Redis -&gt; DB 逻辑    String value = redis.get(key);    if (value == null) &#123;        value = db.query(key);        if (value == null) &#123;            // 配合“缓存空值”方案，双重保险            redis.set(key, &quot;&quot;, 60, TimeUnit.SECONDS);        &#125; else &#123;            redis.set(key, value);        &#125;    &#125;    return value;&#125;\n\n其他方法在请求接受的源头处做一定的过滤，比如说ID的长度为8，那么当请求来的时候可知直接在Controller层拦截掉，这种方法能过滤掉大部分低级的、无脑的恶意攻击。\nRedis持久化简介Redis 的持久化主要为了解决一个问题：Redis 数据存储在内存中，一旦服务器宕机或重启，内存中的数据就会丢失。\n持久化方式RDB工作原理RDB的核心思想是定时拍快照：在指定的时间间隔内，将内存中当前时刻的全量数据生成一个二进制文件（通常命名为dump.rdb）保存到磁盘上。在生产环境中，Redis 几乎总是使用bgsave命令来进行异步持久化，其过程如下：\n\n执行命令：主进程接收到持久化请求（手动或自动触发）。\n创建子进程：主进程调用系统的 fork() 函数创建一个子进程。\n写快照：子进程将当前内存中的数据写入一个临时的 RDB 文件。\n替换原文件：写入完成后，用临时文件替换旧的 dump.rdb 文件。\n\n写时复制：在子进程写快照期间，主进程仍然可以处理写请求。如果主进程修改了某块内存数据，操作系统会为这块数据创建一个副本，主进程在副本上修改，而子进程继续读取原始内存数据进行备份。这样既保证了数据一致性，又不阻塞主进程。\n优缺点优点：\n\n恢复速度极快：RDB 文件是压缩后的紧凑二进制数据，加载速度远快于AOF。\n性能最大化：持久化由子进程处理，主进程不需要进行任何磁盘 IO 操作。\n适合冷备：可以通过备份 dump.rdb 文件（如每天备份一次到云存储），实现异地备份。\n\n缺点：\n\n数据安全性低：RDB的致命伤。因为是间隔触发，如果 Redis 在两次快照之间崩溃，这期间的数据会全部丢失。\n资源损耗：如果内存数据量极大（比如 10GB 以上），fork 子进程的过程可能导致服务器出现明显的秒级停顿。\n\nAOF工作原理AOF 的核心思想是Redis 会将每一个写命令（如 SET、DEL、SADD 等）通过 write 函数追加到 AOF 文件的末尾。当 Redis重启时，会通过重新执行这些命令来在内存中重建整个数据集。AOF 持久化并不是直接写磁盘，而是经过了几个步骤：\n\n命令追加：写命令被追加到服务器系统的 AOF 缓冲区（aof_buf）。\n文件写入与同步：根据设置的策略，将缓冲区内容写入磁盘。\n文件重写：随着文件变大，定期压缩 AOF 文件。\n\n保存策略\n\n\n策略名称\n原理说明\n优点\n缺点\n\n\n\nAlways\n每个写命令执行完，立即同步将日志写回磁盘\n数据最安全，理论上不丢数据\n性能极差，磁盘 IO 开销巨大\n\n\nEverysec\n每个写命令执行完先写入缓冲区，每隔 1 秒将缓冲区内容同步到磁盘\n性能与安全平衡（推荐）\n宕机时可能丢失 1 秒的数据\n\n\nNo\n写命令写入缓冲区后，由操作系统决定何时同步到磁盘\n性能最好\n宕机时丢失数据量不可控\n\n\n重写机制\n由于 AOF 是追加写，文件会越来越大（例如你对一个 Key 执行了 100 次 INCR，AOF 会记录 100 条命令）。为了解决这个问题，Redis 引入了重写机制。Redis 并不需要读取旧的 AOF 文件，而是直接读取内存中的当前数据。它会生成能达到当前数据状态的最少命令。 比如：内存中count 的值是 100。重写前 AOF 有 100 条 INCR；重写后，新 AOF 只有一条 SET count 100。\n触发重写机制的条件：比上次重写后的大小翻倍时且文件至少要达到 64MB。例如：上一次AOF后的文件大小为50M，那么下一次触发重写的时机为50M * 2 &#x3D; 100M的时候才会触发。\n\n优缺点优点：\n\n数据更可靠：默认的 everysec 策略下，最多只丢 1 秒数据。\n日志易读、可修复：AOF 记录的是原始 Redis 命令。如果由于某些原因（磁盘满等）导致末尾指令写破损，可以使用 redis-check-aof工具轻松修复。\n支持“误操作”恢复：如果你不小心执行了 FLUSHALL 命令清空了数据库，只要 AOF 还没被重写，你可以立即停止服务，删掉 AOF 末尾的那条FLUSHALL 指令，重启后数据就全回来了。\n\n缺点：\n\n文件体积大：通常比相同数据集的 RDB 文件大得多。\n恢复速度慢：重启时需要“跑一遍脚本”，如果命令千万级，恢复时间会很久。\n性能压力：虽然是追加写，但在高并发下，频繁的磁盘 IO 还是会比 RDB 略慢。\n\n混合模式（RDB + AOF）工作原理\n持久化过程混合持久化（RDB + AOF）是 Redis 目前最推荐的持久化方案。它的核心逻辑是：利用 RDB 的快速恢复能力，结合 AOF 的数据实时性。在混合使用模式下，AOF 文件的结构会发生变化：它的前半部分是 二进制的 RDB 格式，后半部分是 文本格式的 AOF命令。混合持久化并不是在每一次写命令时发生的，而是在 AOF 重写（Rewrite） 的时候发生的：\n\n\n触发重写：当 AOF 文件体积达到阈值时，Redis 触发后台 AOF 重写。\n创建快照：Redis 会将当前的内存数据以 RDB 二进制 的格式写入新的 AOF 文件开头。\n记录增量：在创建快照期间，主进程收到的写命令会继续以 AOF 文本 格式追加到这个新文件的末尾。\n替换文件：重写完成后，用这个“混合型”文件替换旧的纯文本 AOF 文件。\n\n\n数据恢复当重启 Redis 服务时：\n\n\n识别格式：Redis 首先加载 AOF 文件。\n快速加载：发现开头是 RDB 格式，直接将二进制数据极速载入内存（这省去了大量命令回放的时间）。\n增量重放：加载完 RDB 部分后，继续读取并执行文件末尾的 AOF 命令，恢复重写期间的数据。\n\nRedis主从简介主从复制是 Redis 高可用的基石。它的核心思想是将一台 Redis 服务器（Master，主节点）的数据，实时同步到其他 Redis服务器（Slave&#x2F;Replica，从节点）。 在主从架构中，数据的流动是单向的：只能从主节点流向从节点。使用主从结构主要原因有以下几点：\n\n读写分离：主节点负责写操作，从节点负责读操作。由于大多数互联网场景都是“读多写少”，这能极大地提高系统的吞吐量。\n数据冗余：实现了数据的热备份，是持久化之外的另一种可靠数据保护方式。\n高可用基础：主从复制是哨兵模式和集群模式能够运行的前提。\n\n工作原理Redis 的主从同步分为两个阶段：全量复制和增量复制。\n全量复制（首次连接）当一个从节点第一次连接主节点，或者断开时间太长导致数据无法衔接时，会发生全量复制：\n\n同步请求：从节点发送 psync 命令给主节点。\n生成快照：主节点执行 bgsave 生成 RDB 文件，同时用一个缓冲区记录从现在开始的所有写命令。\n发送 RDB：主节点将 RDB 文件发送给从节点。\n加载数据：从节点清空旧数据，载入 RDB 文件。\n同步缓冲区：主节点把刚才记录在缓冲区的写命令发给从节点，从节点执行这些命令，达到数据一致。\n\n增量复制（网络闪断后）如果主从之间的网络连接断开了很短的时间，重新连接后不需要重新传整个RDB，而是只传断开期间的数据，这里首要介绍一个Offset（偏移量），可以把它想象成一个循环队列，当新的数据量到达环的尾部的时候若此时还有新的数据进来后会覆盖掉最开始的数据，主从节点都会维护一个复制偏移量（一个循环队列）。主从之间会定时发送心跳（默认1s 一次），用于检测链路状态和汇报偏移量。\n\n如果心跳中汇报的 Replica Offset &lt; Master Offset，主节点就会从复制积压缓冲区（Replication BacklogBuffer）中提取缺失的数据，重新发给从节点。\n因为Offset是一个环形数组，如果偏移量已经不在了（被覆盖了），则被迫进行全量同步。\n\n其他\n心跳检测：主从之间会定时发送心跳（默认 1s 一次），用于检测链路状态和汇报偏移量。\n异步复制：主节点处理完写命令后直接给客户端返回成功，然后异步地将命令发给从节点。这意味着主从之间存在微小的数据延迟。\n从节点只读：默认情况下，从节点是只读，这能防止数据被意外修改导致主从不一致。\n\n哨兵模式简介在简单的主从架构中，如果主节点（Master）宕机，必须人工手动将从节点（Slave）提升为主节点，并通知所有应用修改地址。而哨兵机制就是实现这一过程的自动化管家。哨兵是一个特殊的Redis 服务，它不存储数据，而是作为一个独立的进程运行，主要负责三件事：\n\n监控（Monitoring）：哨兵会不断地检查你的主服务器和从服务器是否运作正常。\n通知（Notification）：当被监视的某个 Redis 服务器出现问题时，哨兵可以通过 API 向管理员或其他应用程序发送通知。\n自动故障转移（Automatic Failover）：如果主节点挂了，哨兵会从剩下的从节点中选出一个新的主节点，并让其他从节点改为从属于新主。\n\n哨兵判断主节点是否下线：\n\n主观下线： 单个哨兵发现主节点在指定时间内没有响应（心跳检测超时），它认为这个节点“主观上”挂了。\n客观下线： 当大多数哨兵（达到配置的 quorum 数量，quorum值一般是超过Sentinel实例数量的一半）都认为该主节点已经挂了，那么这个节点就被判定为“客观下线”。此时，故障转移流程正式启动。\n\n工作原理当确认主节点“客观下线”后，哨兵们会进行如下操作：\n选举leader：Sentinel集群要选出一个执行failover的Sentinel节点，所以必须要选出由哪个sentinel来执行。要成为leader要满足两个条件：\n\n最先获得超过半数的投票（Sentinel节点的数量一般设置为奇数，最小从3开始）\n获得的投票数不小于quorum值\n\n而sentinel投票的原则有两条：\n\n优先投票给目前得票最多的\n如果目前没有任何节点的票，就投给自己\n\n例：有3个sentinel节点，s1、s2、s3，假如s2先投票：\n\n此时发现没有任何人在投票，那就投给自己。s2得1票\n接着s1和s3开始投票，发现目前s2票最多，于是也投给s2，s2得3票\ns2称为leader，开始故障转移\n\n所以，通常来说第一个确认master客观下线的人会立刻发起投票，一定会成为leader。但是有极端情况下可能会出现s1,s2,s3都投了自己怎么办，此时会宣告此轮投票失败，所有哨兵会等待一段随机的时间，然后进入下一个纪元（Epoch）重新开始选举。由于等待时间是随机的，下一轮继续按照上述规则进行投票直到选出leader。\n选取新的master新的master会从剩下的slave中选取，选取规则如下：\n\n首先会判断slave节点与master节点断开时间长短，如果超过指定值则会排除该slave节点\n然后判断slave节点的slave-priority值，越小优先级越高，如果是0则永不参与选举\n如果slave-prority一样，则判断slave节点的offset值，越大说明数据越新，优先级越高\n最后是判断slave节点的运行id大小，越小优先级越高。\n\n更换主节点此时选择出来的leader会按照下面顺序来重新执行master：\n\n选出一个 Slave，发送 SLAVE OF NO ONE 让它称为主节点。\n通知其他 Slave 连接新的master。\n发布配置更新，让所有哨兵和客户端知道主节点换人了。\n\nRedis分片集群简介当数据量突破单机物理内存限制（如超过 64GB），或者写操作并发极高单机 Master 无法抗住时，分片集群就派上用场了。如果说“哨兵”是为了高可用，那么“集群”就是为了横向扩展。分片集群采用去中心化的设计，集群中的每个节点都是平等的，彼此通过Gossip 协议 交换状态信息。此时数据不再存在一个节点上，而是分布在多个节点上。客户端可以连接集群中的任意一个节点来访问数据。\n工作原理分片集群中数据的分布机制是通过哈希槽。它没有使用简单的 hash(key) %N，因为节点增减会导致数据大规模迁移。redis中固定是有16384个哈希槽，每个物理节点负责管理一部分槽位，例：\n\n节点 A 负责：0 - 5460\n节点 B 负责：5461 - 10922\n节点 C 负责：10923 - 16383\n\n当需要查询某一个值的时候，先对key进行CRC16 校验，得到一个整数。随后将该值对 16384 取模：$slot &#x3D; CRC16(key) \\pmod{16384}$。此时得到的就是插槽的位置。当节点数增加的时候只会影响每个节点所含有的哈希槽的数量并不会影响该值的存储位置。\n集群的高可用Redis Cluster 内部包含了哨兵的功能。每个“分片”通常由一个主节点和若干个从节点组成。可以看下图更为直观。节点之间互相发送 Ping 包，如果超过半数节点认为某个 Master 挂了，该分片就会触发故障转移。此时改master下会选取一个slave称为新的master并参与到集群中。\n客户端跳转机制 (MOVED 重定向)由于数据分布在不同节点，客户端访问一个 Key 时，如果该 Key 不在当前连接的节点上就会按照下面顺序跳转：\n\n客户端发送命令给节点 A。\n节点 A 计算发现该 Key 属于节点 B 负责的槽位。\n节点 A 返回一个 MOVED 错误（包含节点 B 的 IP 和端口）。\n客户端收到后，自动重定向并连接节点 B 完成请求。\n\n为了防止二次跳转，在某些编程语言中会引入Smart Client（在启动时或运行中，通过 CLUSTER SLOTS 命令获取整个集群的槽位分布图。） 像 Java 的 Jedis 或 Lettuce 这种客户端，会在本地缓存槽位映射表（通常是一个数组，长度为 16384，其中的值为指向节点的内存地址），直接计算出应该请求哪个节点，避免二次跳转。具体流程如下：\n\n缓存路由表：客户端连接集群后，会自动拉取并维护一份本地缓存，记录：Slot 0-5460 -&gt; Node A, Slot 5461-10922 -&gt; Node B 等。\n本地计算：当你执行 SET mykey “hello” 时，客户端在发送请求前，先在本地通过 CRC16(“mykey”) % 16384 算出槽位（假设是 6000）。\n精准打击：查询本地路由表发现 6000 属于 Node B，于是直接建立连接发送给 Node B。整个过程只需一次网络 IO。\n动态更新（故障自愈）：如果集群发生了扩容、缩容或主从切换，导致槽位迁移，原有的缓存就会失效。此时客户端发送请求，Redis 节点会返回 MOVED。Smart Client 收到 MOVED 后，不仅会去请求新节点，还会自动异步更新本地路由表，确保下次请求依然精准。\n\nRedis多线程随着网络硬件的发展（比如万兆网卡），Redis 的性能瓶颈不再是 CPU 或内存，而是网络 IO 的读写。大量的时间消耗在了“从网卡读数据”和“往网卡写数据”这两个动作上。为了解决这个问题 Redis 6.0 引入了 I&#x2F;O 多线程。\n\n主线程：依然负责最重要的 “命令执行”（计算逻辑）。\nI&#x2F;O 线程：负责 “读写网络数据” 和 “协议解析”。\n\nRedis 的 数据读写逻辑（命令执行）依然是单线程的（保证了原子性和无需加锁），但网络数据的收发变成了多线程。如果命令执行变成多线程，Redis 就必须引入 “锁”（Lock）机制来保证数据安全。而加锁和释放锁都是巨大的性能开销，而且还可能会产生死锁问题，除此之外，多线程切换带来的上下文切换损耗，在内存操作这种极快的情况下，反而可能比单线程更慢。\n","categories":["学习"],"tags":["redis","中间件"]},{"title":"IDEA中文件多排显示","url":"/2026/01/19/idea-config/IDEA%E4%B8%AD%E6%96%87%E4%BB%B6%E5%A4%9A%E6%8E%92%E6%98%BE%E7%A4%BA/","content":"问题背景当IDEA中文件打开比较多的时候，会如下图所示，所有的文件都会被隐藏在更多的位置，这样在文件多的时候就不好进行切换。\n解决步骤打开文件多排显示按下图进行设置。\n设置展示文件数可以自行设置一共展示多少个页面，如下图，这个配置不设置也没有问题。\n","categories":["IDEA配置"],"tags":["IDEA","配置"]},{"title":"修改按双shift键快速全局查找","url":"/2026/01/19/idea-config/%E4%BF%AE%E6%94%B9%E6%8C%89%E5%8F%8Cshift%E9%94%AE%E5%BF%AB%E9%80%9F%E5%85%A8%E5%B1%80%E6%9F%A5%E6%89%BE/","content":"问题背景IDEA中默认情况下按两下shift会调出全局查找，但是我在写注释的时候经常需要按shift键切换，因此经常会切出全局查找，因此想修改全局查找按钮。\n操作步骤禁用双shift全局查找功能首先按下图先禁用按两次同一个修饰键触发的功能【例如双shift的全局搜索等】。\n自定义全局搜索按键禁用了双shift启动全局搜索后，我们可以自定义一个全局搜索，配置方法如下，我这里选择的是Alt + f。\n","categories":["IDEA配置"],"tags":["IDEA","配置"]},{"title":"IDEA中的Services启动多个实例的时候不显示端口号","url":"/2026/01/19/idea-config/IDEA%E4%B8%AD%E7%9A%84services%E5%90%AF%E5%8A%A8%E5%A4%9A%E4%B8%AA%E5%AE%9E%E4%BE%8B%E7%9A%84%E6%97%B6%E5%80%99%E4%B8%8D%E6%98%BE%E7%A4%BA%E7%AB%AF%E5%8F%A3%E5%8F%B7/","content":"问题背景在IDEA的Services页面启动应用的时候没有显示端口号，如下图所示。\n解决步骤删除hsperfdata文件夹进入C:\\用户\\你的用户名\\AppData\\Local\\Temp将hsperfdata_你自己用户名这个文件夹删除。也可以使用快捷方式进入Temp文件夹，快捷键win + R后在输入%temp%即可。\n重启IDEA重启IDEA以后再重启刚刚的项目即可。\n","categories":["IDEA配置"],"tags":["IDEA","配置"]},{"title":"断点怎样根据条件拦截","url":"/2026/01/19/idea-config/%E6%96%AD%E7%82%B9%E6%80%8E%E6%A0%B7%E6%A0%B9%E6%8D%AE%E6%9D%A1%E4%BB%B6%E6%8B%A6%E6%88%AA/","content":"问题背景现在有这样一个情况，当我们正在写了一部分代码后，前端提出联调，于是我们在同一个项目里面开启了两个服务如下。当我们在某一行打了断点以后，这个断点会拦截这里所有的请求，比如我正在后台请求的时候【使用8001】，此时前端同时也在请求【使用8000】，就会出现在断点处所有请求都被拦截的情况，但实际上我只想拦截这个8001的请求。\n解决步骤增加断点拦截条件我们在某一行打了断点以后，在断点上右键并按下图配置。这样在改断点处就只会拦截端口号为8001的服务了。注意这里的conditions中是可以使用live_template的，如果该字段经常要使用可以配置一下。\n","categories":["IDEA配置"],"tags":["Java","IDEA","配置","断点"]},{"title":"定时任务(Java)","url":"/2026/01/19/study/%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1(Java)/","content":"@Scheduled简介@Scheduled是基于spring或者spring boot的，该定时任务比较适用于逻辑简单、无需持久化、不涉及跨节点协调。\n执行方式@Scheduled 提供了三种主要的参数来控制执行频率：\n\nfixedRate：新任务以是上一次开始执行时间为基准，不关心上一次任务是否执行完成，如果任务执行时间 &gt;fixedRate，会并发执行（默认单线程除外）。\nfixedDelay：新任务是以上一次结束执行时间为基准，在等待fixedDelay时间间隔后，新任务才会再次执行，所以这种情况是不会存在并发的。\ncron：cron表达式，这种方式的功能最为强大，该表达式的格式为：秒 分 时 日 月 周 年，其中，星号 * 表示所有值，问号 ? 表示不指定值。\n\n示例开启定时任务要使用 @Scheduled，首先需要在Spring Boot的启动类或配置类上添加@EnableScheduling注解。\n启动类加@EnableScheduling@SpringBootApplication@EnableScheduling // 必须开启public class MyApplication &#123;    public static void main(String[] args) &#123;        SpringApplication.run(MyApplication.class, args);    &#125;&#125;\n\n或者（建议使用下面这种，原因在下文中的注意点会说明）\n配置类加@EnableScheduling@Configuration@EnableSchedulingpublic class SchedulerConfig &#123;    @Bean    public TaskScheduler taskScheduler() &#123;        ThreadPoolTaskScheduler scheduler = new ThreadPoolTaskScheduler();        scheduler.setPoolSize(5); // 设置线程池大小        scheduler.setThreadNamePrefix(&quot;scheduled-task-&quot;); //给这个 ThreadPoolTaskScheduler 创建的所有线程，统一加上线程名前缀 schedule-        return scheduler;    &#125;&#125;\n\n写定时任务逻辑在任意受 Spring 管理的 Bean（如 @Component, @Service）的方法上加上注解 @Scheduled：\n@Componentpublic class DataSyncTask &#123;    @Scheduled(fixedRate = 5000)    public void reportCurrentTime() &#123;        System.out.println(&quot;每隔5秒执行一次：&quot; + LocalDateTime.now());    &#125;    @Scheduled(fixedDelay = 5000)    public void reportCurrentTime() &#123;        System.out.println(&quot;每隔5秒执行一次：&quot; + LocalDateTime.now());    &#125;    @Scheduled(cron = &quot;0 0 3 * * ?&quot;) // 每天 3 点执行    public void syncUserData() &#123;        // 同步用户数据逻辑    &#125;&#125;\n\n注意点\n默认情况下，Spring Boot创建的线程池是单线程的，所以多个定时任务是同时串行的，所以强烈建议使用第二种方法创建一个线程池，并设置线程池大小，这里假设大小为5，那么同时就可以执行5个定时任务。而且当某条定时任务卡死后，线程池中剩下的线程还能正常工作不至于真格程序直接卡死。\n在写定时任务的时候，方法名一定要用public，这里涉及到Java中的AOP的底层实现是通过JDK 动态代理，它要求被代理的方法必须是接口中定义的，或者是public 的。\n定时任务的方法通常都是void。\n\nQuartz简介Quartz是OpenSymphony开源组织在Job scheduling领域的一个开源项目，该项目于 2009 年被 Terracotta收购，目前是Terracotta旗下的一个项目。它完全由java编写、可以与J2EE与J2SE应用程序相结合也可以单独使用。Quartz可以用来创建运行十个、百个、乃至几万个Jobs这样复杂的程序。官网：http://www.quartz-scheduler.org/\n工作原理Quartz 任务调度的核心元素是 scheduler, trigger 和 job，其中 trigger 和 job 是任务调度的元数据， scheduler 是实际执行调度的控制器。\nJobJob通常情况下我们需要自行创建要给类去实现Job接口，然后实现execute方法，在该方法中写业务逻辑。每次任务触发时，Quartz 都会重新创建一个全新的Job 实例，执行完后该实例就会被销毁（垃圾回收）。这保证了任务之间是无状态的，互不干扰。\npublic class MyEmailJob implements Job &#123;    @Override    public void execute(JobExecutionContext context) &#123;        System.out.println(&quot;正在发送邮件...&quot;);    &#125;&#125;\n\nJobDetailJobDetail 是一个具体对象。它定义了“这个任务叫什么、属于谁、需要哪些参数”。它是 Job 的配置信息。由于 Job 接口每次都会创建新对象，Quartz需要一个持久化的“说明书”来记录这个任务的具体信息。可以把Job看成模具，JobDetail 是根据模具生产出来的具体产品（拥有自己的编号、颜色和标签）。\nJobDetail jobDetail = JobBuilder.newJob(MyEmailJob.class) // 创建jobDetail,并选择包装的任务类        .withIdentity(&quot;myEmailJob&quot;, &quot;group1&quot;)        .usingJobData(&quot;userId&quot;, 123)        .storeDurably()        .build();\n\n\nwithIdentity(“myEmailJob”, “group1”) ：这个是任务全局唯一的标志，防止创建多个相同的任务。\nusingJobData(“userId”, 123)：这个看下文。\nstoreDurably()：表示当前任务可以持久化，正常情况下，JobDetail必须要和Trigger相关联，当关联的Trigger被销毁时，该JobDetail也会被销毁，但是如果加了这个参数的话，该JobDetail可以在不依附Trigger的情况在独立存在。\n\nJobDataMapJobDataMap 是实现“任务逻辑”与“任务数据”解耦的关键。它本质上是一个经过封装的 Map，专门用于在任务定义时存储参数，并在任务执行时传递参数。由于Quartz 每次执行任务时都会重新实例化 Job 类，如果你在 Job 类中定义成员变量（比如 private StringuserId），这些变量是无法在多次执行间保持状态或从外部获取初值的。举个例子：我们在Job的任务逻辑中需要根据当前userId的不同来做不同的操作，而这个userId是个变量，我无法直接写死在Job中，所以只能在创建JobDetail的时候或者是创建Trigger的时候将userId通过JobDataMap传递给Job，使得该变量在Job中可以使用。\n@Componentpublic class QuartzTest &#123;    @PostConstruct    public void startQuartzJob() throws SchedulerException &#123;        // 1 .创建Quartz的任务调度器        Scheduler scheduler = StdSchedulerFactory.getDefaultScheduler();        // 2 .创建触发器        SimpleScheduleBuilder simpleScheduleBuilder = SimpleScheduleBuilder.simpleSchedule()                .withIntervalInSeconds(3)                .withRepeatCount(10).withMisfireHandlingInstructionNextWithRemainingCount();        SimpleTrigger trigger = TriggerBuilder.newTrigger()                .withIdentity(&quot;trigger1&quot;, &quot;group1&quot;)                .withSchedule(simpleScheduleBuilder)                .usingJobData(&quot;key1&quot;, &quot;value1&quot;)  // 设置Trigger参数                .build();        // 3 .创建任务(JobDetail  用于封装具体的任务)        JobDetail job = JobBuilder.newJob(QuartzTask.class)                .withIdentity(&quot;job1&quot;, &quot;group1&quot;)                .usingJobData(&quot;key2&quot;, &quot;value2&quot;)    // 设置JobDetail参数                .build();        scheduler.scheduleJob(job, trigger);        scheduler.start();    &#125;&#125;\n\n在job的执行过程中，可以从JobDataMap中取出数据，如下示例：\npublic class QuartzTask implements Job &#123;    @Override    public void execute(JobExecutionContext jobExecutionContext) throws JobExecutionException &#123;        // 1.获取trigger中传递的参数        JobDataMap jobDataMap_1 = jobExecutionContext.getTrigger().getJobDataMap();        String value_1 = jobDataMap_1.get(&quot;key1&quot;).toString();        // 2.获取JobDetail中传递的参数        JobDataMap jobDataMap_2 = jobExecutionContext.getJobDetail().getJobDataMap();        String value_2 = jobDataMap_2.get(&quot;key2&quot;).toString();        System.out.println(&quot;jobDataMap_trigger_value:&quot; + value_1 + &quot;jobDataMap_jobDetail_value:&quot; + value_2);    &#125;&#125;\n\nTriggerTrigger（触发器）是决定任务何时执行的核心组件。如果说 Job 是执行逻辑的什么，那么 Trigger就是触发逻辑的时间表。Quartz 中主要提供了以下四种类型的 Trigger，可以满足企业应用中的绝大部分需求：\n\nSimpleTrigger: 使用简单便捷\nCronTirgger: 使用cron表达式定义触发任务的时间规则\nDateIntervalTrigger: 日期周期的规则的触发器\nNthIncluded DayTrigger: 排除指定时间周期和日期的触发器\n\nSimpleTriggerSimpleTrigger可以满足的调度需求是：在具体的时间点执行一次，或者在具体的时间点执行，并且以指定的间隔重复执行若干次。\n\n延时任务：当用户提交订单之后启动任务，延时30min检查订单状态，如果未支付则取消订单释放库存\n循环任务：每个指定的时间周期执行一次任务，任务可以循环（可以无限循环、可以循环指定的次数、还可 以循环执行到指定的时间点）\n定时任务：在指定的时间点调度执行任务\n\n//【实例1】指定时间开始触发，不重复SimpleTrigger trigger = TriggerBuilder.newTrigger()                .withIdentity(&quot;trigger1 &quot;, &quot;group1&quot;) // 触发器的唯一标识 name + group                .startAt(myStartTime)  //  指定任务开始的时间                .build();\n\n//【实例2】指定时间触发，每隔10秒执行一次，重复10次SimpleScheduleBuilder simpleScheduleBuilder = SimpleScheduleBuilder.simpleSchedule()                .withIntervalInSeconds(10)                .withRepeatCount(10);SimpleTrigger trigger = TriggerBuilder.newTrigger()        .withIdentity(&quot;trigger1&quot;, &quot;group1&quot;)        .startAt(new Date(System.currentTimeMillis() + 5000))        .withSchedule(simpleScheduleBuilder) // 绑定重复调度策略        .forJob(JobBuilder.newJob(QuartzTask.class).build())  // 将触发器和任务绑定        .build();\n\n//【实例3】5分钟以后开始触发，仅执行一次// 获取当前时间点往后推算某个时间之后的时间点Trigger trigger = TriggerBuilder.newTrigger()                .withIdentity(&quot;trigger1&quot;, &quot;group1&quot;)                .startAt(DateBuilder.futureDate(5, DateBuilder.IntervalUnit.MINUTE)) // 5分钟后开始执行                .forJob(JobBuilder.newJob(QuartzTask.class).build())                .build();\n\n//【实例4】立即触发，每隔5分钟执行一次，直到22 :00：SimpleScheduleBuilder schedule = SimpleScheduleBuilder.simpleSchedule()                .withIntervalInMinutes(5)                .repeatForever(); // 这里的重复次数一定要写，否则只执行一次SimpleTrigger trigger = TriggerBuilder.newTrigger()        .withIdentity(&quot;trigger1&quot;, &quot;group1&quot;)        .startAt(new Date(System.currentTimeMillis()))        .endAt(DateBuilder.dateOf(22, 0, 0))        .withSchedule(schedule)        .build();\n\n//【案例5】建立一个触发器，将在下一个小时的整点触发，然后每2小时重复一次SimpleScheduleBuilder schedule = SimpleScheduleBuilder.simpleSchedule()                .withIntervalInHours(2)                .repeatForever(); // 这里的重复次数一定要写，否则只执行一次SimpleTrigger trigger = TriggerBuilder.newTrigger()        .withIdentity(&quot;trigger1&quot;, &quot;group1&quot;)        .startAt(DateBuilder.evenHourDate(null))        .withSchedule(schedule)        .build();\n\nSimpleScheduleBuilder simpleScheduleBuilder = SimpleScheduleBuilder.simpleSchedule()        .withIntervalInSeconds(3).repeatForever()        // .withMisfireHandlingInstructionFireNow()        // .withMisfireHandlingInstructionIgnoreMisfires ()        // .withMisfireHandlingInstructionNextWithExistingCount()        // .withMisfireHandlingInstructionNextWithRemainingCount()        // .withMisfireHandlingInstructionNowWithExistingCount()        .withMisfireHandlingInstructionNowWithRemainingCount();SimpleTrigger trigger = TriggerBuilder.newTrigger()        .withIdentity(&quot;trigger1 &quot;, &quot;group1&quot;)        .withSchedule(simpleScheduleBuilder)        .build();\n\n\nwithIdentity：这个同上\nstartAt：开始时刻\nendAt：结束时刻\nwithSchedule：负责定义出触发的规则，例如：任务一共执行几次，任务执行的间隔时间，任务执行的时间间隔单位等。\nforJob：将触发器绑定了Job上，正常情况下是通过下方这种情况来绑定JobDetail和Trigger的。\n\nScheduler scheduler = StdSchedulerFactory.getDefaultScheduler();scheduler.scheduleJob(jobDetail, trigger);\n\n但是如果当前有这样一个情况，当前JobDetail和Trigger1已经通过scheduler.scheduleJob(jobDetail, trigger1)的方式绑定了，如果再通过scheduler.scheduleJob(jobDetail, trigger2)的方式再绑定就会报错，如下：所以此时我们只能通过如下方式才能将JobDetail和Trigger2进行绑定。\nSimpleTrigger trigger2 = TriggerBuilder.newTrigger()        .withIdentity(&quot;trigger2&quot;, &quot;group1&quot;)  //触发器的唯一标识 name + group        .startAt(new Date(System.currentTimeMillis() + 5000)) // 定时任务的启动时机        .withSchedule(simpleScheduleBuilder) // 绑定重复调度的策略        .forJob(jobDetail)        .build();scheduler.scheduleJob(trigger2);\n\n\nMisfire策略：上述例子中的withMisfireHandlingInstructionNowWithRemainingCount属于Misfire策略，当已经绑定到调度器Scheduler的触发器及任务在执行的过程中，因Scheduler出现故障停止了、或者线程池中没有充足的线程执行到期的任务，从而导致Trigger触发周期到了但是任务没有执行的情况——Misfire对于支持持久化的Trigger，可以通过指定Misfire策略，来定义其恢复之后的执行策略对于所有类型的Trigger ，Quartz都为其指定了默认的misfire策略——MISFIRE_INSTRUCTION_SMART_POLICY（立即执行misfire的任务，然后继续按计划往后执行）。SimpleTrigger的Misfire策略提供了六种如下:\n\n#  当资源可用时立即执行所有misfire的任务，执行到设置的endTime剩余的周期次数MISFIRE_INSTRUCTION_FIRE_NOW#  不会判断misfire ，当资源可用时立即执行所有misfire的任务，然后按照原计划执行MISFIRE_INSTRUCTION_IGNORE_MISFIRE_POLICY#  立即执行第一次misfire任务，修改startTime为当前时间，按照原来的时间间隔执行下一次任务（总次数不变）MISFIRE_INSTRUCTION_RESCHEDULE_NOW_WITH_EXISTING_REPEAT_COUNT#  立即执行第一次misfire任务，修改startTime为当前时间，按照原来的时间间隔执行下一次任务（剩下的任务）MISFIRE_INSTRUCTION_RESCHEDULE_NOW_WITH_REMAINING_REPEAT_COUNT#  不会立即执行任务，等到下一次计划时间到达时开始执行，忽略已经发生的misfire任务MISFIRE_INSTRUCTION_RESCHEDULE_NEXT_WITH_EXISTING_COUNT#  不会立即执行任务，等到下一次计划时间到达时开始执行，忽略已经发生的misfire任务MISFIRE_INSTRUCTION_RESCHEDULE_NEXT_WITH_REMAINING_COUNT\n\nCronTriggerCronTrigger通常比SimpleTrigger更有用，如果需要基于日历的概念而不是按照SimpleTrigger的精确指定间隔进行重新启动的作业启动计划。\n// 构造cron表达式CronScheduleBuilder cronScheduleBuilder = CronScheduleBuilder.cronSchedule(&quot;0/5 * * * * ?&quot;);CronTrigger trigger = TriggerBuilder.newTrigger()        .withIdentity(&quot;trigger1&quot;, &quot;group1&quot;)        .startAt(DateBuilder.futureDate(5, DateBuilder.IntervalUnit.SECOND))        .withSchedule(cronScheduleBuilder)        .build();\n\nCronScheduleBuilder cronScheduleBuilder = CronScheduleBuilder.cronSchedule(&quot;0 0 12 ? * MON#1 2022&quot;)        // .withMisfireHandlingInstructionIgnoreMisfires ()        // .withMisfireHandlingInstructionDoNothing()        .withMisfireHandlingInstructionFireAndProceed();CronTrigger cronTrigger = (CronTrigger) TriggerBuilder.newTrigger()        .withIdentity(&quot;cronTrigger1 &quot;, &quot;group1&quot;)        .withSchedule(cronScheduleBuilder)        .build();\n\n\nMisfire策略:定义同上，在Quartz中，CronTrigger的Misfire策略提供了以下三种：\n\n#  立即执行所有的misfire任务，然后继续按计划执行MISFIRE_INSTRUCTION_IGNORE_MISFIRE_POLICY#  发生的misfire的任务都会被忽略，从当前时间按照原计划执行MISFIRE_INSTRUCTION_DO_NOTHING#  立即执行第一个发生misfire的任务，忽略其他misfire的任务，然后按照原计划继续执行MISFIRE_INSTRUCTION_FIRE_ONCE_NOW    \n\nSchedulerScheduler 是一个接口，定义了操作任务的所有方法。它并不直接执行任务，而是通过线程池（ThreadPool来调度任务执行。简单点来说，他们就想将JobDetail和Trigger进行绑定，然后交给Scheduler进行调度执行。通常情况下Scheduler有几种分类如下：\n\nStdScheduler：这是最长使用的种类，StdSchedulerFactory在创建scheduler时会读取quartz.properties，创建ThreadPool和JobStore，最后组装成一个 QuartzScheduler并返回一个Scheduler代理对象。\n\nScheduler scheduler = StdSchedulerFactory.getDefaultScheduler();\n\n\nDirectScheduler：这种 Scheduler 是完全由手动控制，他不会读取quartz.properties，所有的组件都必须要自己来提供。普通业务并不推荐这种方式。\n\nDirectSchedulerFactory factory = DirectSchedulerFactory.getInstance();ThreadPool threadPool = new SimpleThreadPool(10, Thread.NORM_PRIORITY);JobStore jobStore = new RAMJobStore();factory.createScheduler(        &quot;myScheduler&quot;,                &quot;AUTO&quot;,        threadPool,        jobStore        );\n\n\nSchedulerFactoryBean：这个是Spring体系中的标准，其本质还是StdScheduler，只是Spring 对 Quartz 的进行了封装，具体使用方法看下文。\n\n示例普通项目\n添加quertz依赖\n\n&lt;dependency&gt;    &lt;groupId&gt;org.quartz-scheduler&lt;/groupId&gt;    &lt;artifactId&gt;quartz&lt;/artifactId&gt;    &lt;version&gt;2.3.2&lt;/version&gt;&lt;/dependency&gt;\n\n\n创建任务\n\n编写任务逻辑public class QuartzTask implements Job &#123;    @Override    public void execute(JobExecutionContext jobExecutionContext) throws JobExecutionException &#123;        System.out.println(&quot;QuartzTask执行了: &quot; + LocalDateTime.now());    &#125;&#125;\n\n\n启动任务\n\n启动任务@Componentpublic class QuartzTest &#123;    @PostConstruct    public void startQuartzJob() throws SchedulerException &#123;        // 1.创建quartz任务调度器        Scheduler scheduler = StdSchedulerFactory.getDefaultScheduler();        // 2.创建任务        JobDetail jobDetail = JobBuilder.newJob(MyJob.class).build();        // 3.创建触发器，用来定义任务调度的时机（例如：延时，循环，定时...）        SimpleScheduleBuilder simpleScheduleBuilder = SimpleScheduleBuilder.simpleSchedule()                .withIntervalInSeconds(5) // 间隔时间,每隔5秒执行一次                .withRepeatCount(10); // 重复次数，不算首次，一共重复执行10次，所以一共会执行11次，如果不设置，这里默认情况下为0        SimpleTrigger trigger1 = TriggerBuilder.newTrigger()                .withIdentity(&quot;trigger1&quot;, &quot;group1&quot;)  //触发器的唯一标识 name + group                .startAt(new Date(System.currentTimeMillis() + 5000)) // 定时任务的启动时机                .withSchedule(simpleScheduleBuilder) // 绑定重复调度的策略                .build();        SimpleTrigger trigger2 = TriggerBuilder.newTrigger()                .withIdentity(&quot;trigger2&quot;, &quot;group1&quot;)  //触发器的唯一标识 name + group                .startAt(new Date(System.currentTimeMillis() + 5000)) // 定时任务的启动时机                .withSchedule(simpleScheduleBuilder) // 绑定重复调度的策略                .forJob(jobDetail)                .build();        // 4.将触发器和任务绑定到任务调度器        scheduler.scheduleJob(jobDetail, trigger1);        scheduler.scheduleJob(trigger2);        // 5.开始定时任务        scheduler.start();    &#125;&#125;\n\nSpringboot项目\n添加quertz依赖\n\n&lt;dependency&gt;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    &lt;artifactId&gt;spring-boot-starter-quartz&lt;/artifactId&gt;&lt;/dependency&gt;\n\n\n添加配置文件\n\nspring:  quartz:    job-store-type: jdbc    jdbc:      initialize-schema: never\n\n\n创建Quartz相关的表根据GitHub上的教程来导入所必须的sql表。GitHub地址可点击此下载\n\n创建任务逻辑这一块和上述一样\n\n\npublic class MyJob extends QuartzJobBean &#123;    @Override    protected void executeInternal(JobExecutionContext context) throws JobExecutionException &#123;        System.out.println(&quot;Springboot Quartz start&quot;);    &#125;&#125;\n\n这里继承QuartzJobBean是Spring里面的写法，在Spring项目中也推荐这样写，对于实现Job接口来说，这种写可以在文件中使用@Autowired。\n\n创建定时任务并绑定触发器和任务\n\n@Configurationpublic class QuartzConfig &#123;    @Bean    public JobDetail getJobDetail() &#123;        return JobBuilder.newJob(MyJob.class)                .withIdentity(&quot;job1&quot;, &quot;group1&quot;)                .storeDurably()  // 设置当前任务持久化                .build();    &#125;    @Bean    public CronTrigger getCronTrigger(JobDetail jobDetail) &#123;        return TriggerBuilder.newTrigger()                .withIdentity(&quot;trigger1&quot;, &quot;group1&quot;)                .withSchedule(CronScheduleBuilder.cronSchedule(&quot;0/5 * * * * ?&quot;))                .usingJobData(&quot;name&quot;, &quot;维什戴尔&quot;)                .forJob(jobDetail)  //触发器绑定job  (一个触发器只能绑定一个job ，一个job可以被多个触发器绑定)                .build();    &#125;    @Bean(&quot;trigger&quot;)    public CronTrigger getCronTrigger_2(JobDetail jobDetail) &#123;        return TriggerBuilder.newTrigger()                .withIdentity(&quot;trigger2&quot;, &quot;group1&quot;)                .withSchedule(CronScheduleBuilder.cronSchedule(&quot;0/5 * * * * ?&quot;))                .usingJobData(&quot;name&quot;, &quot;逻各斯&quot;)                .forJob(jobDetail)                .build();    &#125;&#125;\n\nspring项目中，quartzScheduler是quartz包里面自带的，我们不需要在手动创建和绑定了。\n其他定时任务的其他操作实际上，在Quartz中除了能增加任务以外，还可以暂停，重启，删除任务，下面给出实际开发中用到的代码：\n暂停定时任务/** * 暂停定时任务 * * @param jobId 任务ID * @return 响应结果 */@PostMapping(&quot;/pauseJob&quot;)public ResultBean pauseJob(@RequestParam String jobId) &#123;    log.info(&quot;暂停任务&quot;);    try &#123;        Scheduler scheduler = schedulerFactoryBean.getScheduler();        JobKey jobKey = new JobKey(&quot;RecentAccessRulesScanTask&quot;, &quot;RecentAccessJob_&quot; + jobId);        // 检查目标Job是否正在运行中        JobDetail jobDetail = scheduler.getJobDetail(jobKey);        if (jobDetail == null) &#123;            return ResultBean.success(false);        &#125;        scheduler.pauseJob(jobKey);    &#125; catch (SchedulerException e) &#123;        e.printStackTrace();        return ResultBean.success(false);    &#125;    return ResultBean.success(true);&#125;\n\n恢复定时任务/** * 恢复定时任务 * * @param jobId 任务ID * @return 响应结果 */@PostMapping(&quot;/resumeJob&quot;)public ResultBean resumeJob(@RequestParam String jobId) &#123;    log.info(&quot;恢复任务&quot;);    try &#123;        Scheduler scheduler = schedulerFactoryBean.getScheduler();        JobKey jobKey = new JobKey(&quot;RecentAccessRulesScanTask&quot;, &quot;RecentAccessJob_&quot; + jobId);        JobDetail jobDetail = scheduler.getJobDetail(jobKey);        if (jobDetail == null) &#123;            return ResultBean.success(false);        &#125;        scheduler.resumeJob(jobKey);    &#125; catch (SchedulerException e) &#123;        e.printStackTrace();        return ResultBean.success(false);    &#125;    return ResultBean.success(true);&#125;\n\n删除定时任务/** * 删除定时任务 * * @param jobId 任务ID * @return 响应结果 */@PostMapping(&quot;/deleteJob&quot;)public ResultBean deleteJob(@RequestParam String jobId) &#123;    log.info(&quot;删除任务&quot;);    try &#123;        Scheduler scheduler = schedulerFactoryBean.getScheduler();        JobKey jobKey = new JobKey(&quot;RecentAccessRulesScanTask&quot;, &quot;RecentAccessJob_&quot; + jobId);        JobDetail jobDetail = scheduler.getJobDetail(jobKey);        if (jobDetail == null) &#123;            return ResultBean.success(false);        &#125;        scheduler.deleteJob(jobKey);    &#125; catch (SchedulerException e) &#123;        e.printStackTrace();        return ResultBean.success(false);    &#125;    return ResultBean.success(true);&#125;\n\nListener监听器Quartz供了监听器，用于监听调度器、触发器及任务的相关事件。\nJobListener\n创建监听\n\npublic class MyJobListener implements JobListener &#123;    // getName返回此监听器的唯一标识字符串    @Override    public String getName() &#123;        return &quot;MyJobListener&quot;;    &#125;    // 监听任务开始执行事件，在任务开始之前触发此监听方法    @Override    public void jobToBeExecuted(JobExecutionContext jobExecutionContext) &#123;        System.out.println(&quot;-------jobToBeExecuted-------&quot;);    &#125;    // 监听任务开始失效事件，在任务失效触发此监听方法    @Override    public void jobExecutionVetoed(JobExecutionContext jobExecutionContext) &#123;        System.out.println(&quot;------jobExecutionVetoed------&quot;);    &#125;    // 监听任务执行完成事件，在任务执行结束之前触发此监听方法    @Override    public void jobWasExecuted(JobExecutionContext jobExecutionContext, JobExecutionException e) &#123;        System.out.println(&quot;-------jobWasExecuted-------&quot;);    &#125;&#125;\n\n\n注册监听器\n\n\n普通项目\n\n// a.监听当前调度器上的所有任务scheduler.getListenerManager()    .addJobListener(new MyJobListener());// b.监听group1任务组中的所有任务scheduler.getListenerManager()        .addJobListener(new MyJobListener(), GroupMatcher.jobGroupEquals(&quot;group1&quot;));// c.监听某个特定任务scheduler.getListenerManager()        .addJobListener(new MyJobListener(), KeyMatcher.keyEquals(new JobKey(&quot;job1 &quot;, &quot;group1&quot;)));\n\n\nspringboot项目\n\n注册监听器@Configurationpublic class QuartzListenerConfig &#123;    @Autowired    private MyJobListener myJobListener;    @Bean    public SchedulerFactoryBean schedulerFactoryBean(DataSource dataSource) &#123;        SchedulerFactoryBean factory = new SchedulerFactoryBean();        factory.setDataSource(dataSource);        factory.setGlobalJobListeners(myJobListener);        return factory;    &#125;&#125;\n\n结果如下：\nTriggerListener\n创建触发器监听器\n\nimport org.quartz.*;import org.springframework.stereotype.Component;@Componentpublic class MyTriggerListener implements TriggerListener &#123;    @Override    public String getName() &#123;        return &quot;myTriggerListener&quot;;    &#125;    @Override    public void triggerFired(Trigger trigger, JobExecutionContext context) &#123;        System.out.println(&quot;Trigger fired: &quot; + trigger.getKey());    &#125;    @Override    public boolean vetoJobExecution(Trigger trigger, JobExecutionContext context) &#123;        // 返回 true 可以阻止 Job 执行        return false;    &#125;    @Override    public void triggerMisfired(Trigger trigger) &#123;        System.out.println(&quot;Trigger misfired: &quot; + trigger.getKey());    &#125;    @Override    public void triggerComplete(Trigger trigger,                                JobExecutionContext context,                                Trigger.CompletedExecutionInstruction triggerInstructionCode) &#123;        System.out.println(&quot;Trigger complete: &quot; + trigger.getKey());    &#125;&#125;\n\n\n注册触发器监听器\n\n\n普通项目\n\n注册触发器监听器scheduler.getListenerManager().addTriggerListener(new MyTriggerListener());\n\n\nSpringBoot项目\n\n@Configurationpublic class QuartzConfig &#123;    @Autowired    private MyTriggerListener myTriggerListener;    @Bean    public SchedulerFactoryBean schedulerFactoryBean() &#123;        SchedulerFactoryBean factory = new SchedulerFactoryBean();        // 注册全局 TriggerListener        factory.setGlobalTriggerListeners(myTriggerListener);        return factory;    &#125;&#125;\n\nSchedulerListener\n创建调度器监听器\n\nimport org.quartz.*;import org.springframework.stereotype.Component;@Componentpublic class MySchedulerListener implements SchedulerListener &#123;    @Override    public void jobAdded(JobDetail jobDetail) &#123;        System.out.println(&quot;Job added: &quot; + jobDetail.getKey());    &#125;    @Override    public void jobDeleted(JobKey jobKey) &#123;        System.out.println(&quot;Job deleted: &quot; + jobKey);    &#125;    @Override    public void triggerFinalized(Trigger trigger) &#123;        System.out.println(&quot;Trigger finalized: &quot; + trigger.getKey());    &#125;    @Override    public void schedulerStarted() &#123;        System.out.println(&quot;Scheduler started&quot;);    &#125;    @Override    public void schedulerShutdown() &#123;        System.out.println(&quot;Scheduler shutdown&quot;);    &#125;    @Override    public void schedulingDataCleared() &#123;        System.out.println(&quot;Scheduler cleared all data&quot;);    &#125;    @Override    public void jobPaused(JobKey jobKey) &#123;        System.out.println(&quot;Job paused: &quot; + jobKey);    &#125;    @Override    public void jobResumed(JobKey jobKey) &#123;        System.out.println(&quot;Job resumed: &quot; + jobKey);    &#125;    @Override    public void triggerPaused(TriggerKey triggerKey) &#123;        System.out.println(&quot;Trigger paused: &quot; + triggerKey);    &#125;    @Override    public void triggerResumed(TriggerKey triggerKey) &#123;        System.out.println(&quot;Trigger resumed: &quot; + triggerKey);    &#125;&#125;\n\n\n注册调度器监听器\n\n\n普通项目\n\nMySchedulerListener mySchedulerListener = new MySchedulerListener();scheduler.getListenerManager().addSchedulerListener(mySchedulerListener);scheduler.getListenerManager().removeSchedulerListener(mySchedulerListener);\n\n\nSpringBoot项目\n\n@Configurationpublic class QuartzConfig &#123;    @Autowired    private MySchedulerListener mySchedulerListener;    @Bean    public SchedulerFactoryBean schedulerFactoryBean() &#123;        SchedulerFactoryBean factory = new SchedulerFactoryBean();        // 注册全局 SchedulerListener        factory.setSchedulerListeners(mySchedulerListener);        return factory;    &#125;&#125;\n\nQuartz久化\nJobStore：JobStore负责存储调度器的“工作数据”：任务（Job），触发器（Trigger），数据（Job DataMap），通俗的讲：JobStore中存储的是什么，调度器就执行什么。\nJDBCJobStore：比如我们要执行100次任务，当执行了40次时系统崩溃了，系统重启时任务的执行计数器默认会从0开始。这种策略能够满足多数业务场景需求；但是在某个特定的场景中我们需要继续之前的任务执行，我们可以通过对JobStore进行持久化来实现。为此Quartz提供了两种作业类型：\nRAMJobStore 基于内存存储调度器的工作数据 优点：速度快 缺点：不支持持久化\nJDBCJobStore 基于数据库存储调度器的工作数据 优点：支持持久化,支持quartz集群 缺点：速度慢\n\n\n\n通过修改quartz的属性配置，将quartz的JobStore修改为JDBCJobStore，并配置数据源；如果是集群部署，只需多个调度器的JDBCJobStore使用相同的数据源即可。\nxxl-job简介XXL-Job：是大众点评的分布式任务调度平台，是一个轻量级分布式任务调度平台, 其设计思想将调度行为抽象形成“调度中心”公共平台，而平台自身并不承担业务逻辑，“调度中心”负责发起调度请求。 将任务抽象成分散的JobHandler，交由“执行器”统一管理，“执行器”负责接收调度请求并执行对应的JobHandler中业务逻辑。 因此，“调度”和“任务”两部分可以相互解耦，提高系统整体稳定性和扩展性。使用xxl分布式调度主要是以下几点：\n\n高可用：单机版的定时任务调度只能在一台机器上运行，如果程序或者系统出现异常就会导致功能不可用。\n防止重复执行: 在单机模式下，定时任务是没什么问题的。但当我们部署了多台服务，同时又每台服务又有定时任务时，若不进行合理的控制在同一时间，只有一个定时任务启动执行，定时执行的结果就可能存在混乱和错误了。\n单机处理极限：原本1分钟内需要处理1万个订单，但是现在需要1分钟内处理10万个订单；原来一个统计需要1小时，现在业务方需要10分钟就统计出来。你也许会说，你也可以多线程、单机多进程处理。的确，多线程并行处理可以提高单位时间的处理效率，但是单机能力毕竟有限（主要是CPU、内存和磁盘），始终会有单机处理不过来的情况。\n\n系统架构图：\n快速入门\n下载源码：https://github.com/xuxueli/xxl-jobhttps://gitee.com/xuxueli0323/xxl-job\n\n初始化调度数据库：点击下载\n\n下载源码：点击下载\n\n配置部署调度中心修改xxl-job-admin项目的配置文件application.properties,把数据库账号密码配置上\n\n\n### webserver.port=8080server.servlet.context-path=/xxl-job-admin### actuatormanagement.server.servlet.context-path=/actuatormanagement.health.mail.enabled=false### resourcesspring.mvc.servlet.load-on-startup=0spring.mvc.static-path-pattern=/static/**spring.resources.static-locations=classpath:/static/### freemarkerspring.freemarker.templateLoaderPath=classpath:/templates/spring.freemarker.suffix=.ftlspring.freemarker.charset=UTF-8spring.freemarker.request-context-attribute=requestspring.freemarker.settings.number_format=0.############# mybatismybatis.mapper-locations=classpath:/mybatis-mapper/*Mapper.xml#mybatis.type-aliases-package=com.xxl.job.admin.core.model### xxl-job, datasourcespring.datasource.url=jdbc:mysql://192.168.202.200:3306/xxl_job?useUnicode=true&amp;characterEncoding=UTF-8&amp;autoReconnect=true&amp;serverTimezone=Asia/Shanghaispring.datasource.username=rootspring.datasource.password=WolfCode_2017spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver### datasource-poolspring.datasource.type=com.zaxxer.hikari.HikariDataSourcespring.datasource.hikari.minimum-idle=10spring.datasource.hikari.maximum-pool-size=30spring.datasource.hikari.auto-commit=truespring.datasource.hikari.idle-timeout=30000spring.datasource.hikari.pool-name=HikariCPspring.datasource.hikari.max-lifetime=900000spring.datasource.hikari.connection-timeout=10000spring.datasource.hikari.connection-test-query=SELECT 1spring.datasource.hikari.validation-timeout=1000### xxl-job, emailspring.mail.host=smtp.qq.comspring.mail.port=25spring.mail.username=xxx@qq.comspring.mail.from=xxx@qq.comspring.mail.password=xxxspring.mail.properties.mail.smtp.auth=truespring.mail.properties.mail.smtp.starttls.enable=truespring.mail.properties.mail.smtp.starttls.required=truespring.mail.properties.mail.smtp.socketFactory.class=javax.net.ssl.SSLSocketFactory### xxl-job, access tokenxxl.job.accessToken=default_\n\n\n启动调度中心运行XxlJobAdminApplication程序，访问调度中心地址：http://localhost:8080/xxl-job-admin 。默认账号密码：admin&#x2F;123456，看到下图表示部署成功。\n\n配置部署执行器项目该项目中已经配备了两个例子，一个是无框架的原始示例，一个有SpringBoot框架的示例。我们这里面用第二个。\n\n\n这里要注意，案例中已经部分配置已经完成，如果是新项目需要引入下面这个依赖：\n&lt;dependency&gt;    &lt;groupId&gt;com.xuxueli&lt;/groupId&gt;    &lt;artifactId&gt;xxl-job-core&lt;/artifactId&gt;    &lt;version&gt;2.3.1&lt;/version&gt;&lt;/dependency&gt;\n\n7. \n","categories":["学习"],"tags":["Java","定时任务"]}]