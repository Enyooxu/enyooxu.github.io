[{"title":"Mybatis-Plus与Springboot版本冲突","url":"/2026/01/19/error/Mybatis-Plus%E4%B8%8ESpringboot%E7%89%88%E6%9C%AC%E5%86%B2%E7%AA%81/","content":"问题背景创建一个新项目后，引入了mybatis-plus,完成最基础的几个类，然后直接运行出现以下报错。\norg.springframework.beans.factory.BeanDefinitionStoreException: Invalid bean definition with name &#x27;userMapper&#x27; defined in file [D:\\Project\\demo\\target\\classes\\com\\example\\demo\\mapper\\UserMapper.class]: Invalid value type for attribute &#x27;factoryBeanObjectType&#x27;: java.lang.String        at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.getTypeForFactoryBean(AbstractAutowireCapableBeanFactory.java:864) ~[spring-beans-6.2.8.jar:6.2.8]        at org.springframework.beans.factory.support.AbstractBeanFactory.getType(AbstractBeanFactory.java:745) ~[spring-beans-6.2.8.jar:6.2.8]        at org.springframework.beans.factory.support.DefaultListableBeanFactory.findAnnotationOnBean(DefaultListableBeanFactory.java:817) ~[spring-beans-6.2.8.jar:6.2.8]        at org.springframework.boot.sql.init.dependency.AnnotationDependsOnDatabaseInitializationDetector.detect(AnnotationDependsOnDatabaseInitializationDetector.java:36) ~[spring-boot-3.4.7.jar:3.4.7]        at org.springframework.boot.sql.init.dependency.DatabaseInitializationDependencyConfigurer$DependsOnDatabaseInitializationPostProcessor.detectDependsOnInitializationBeanNames(DatabaseInitializationDependencyConfigurer.java:152) ~[spring-boot-3.4.7.jar:3.4.7]        at org.springframework.boot.sql.init.dependency.DatabaseInitializationDependencyConfigurer$DependsOnDatabaseInitializationPostProcessor.postProcessBeanFactory(DatabaseInitializationDependencyConfigurer.java:115) ~[spring-boot-3.4.7.jar:3.4.7]        at org.springframework.context.support.PostProcessorRegistrationDelegate.invokeBeanFactoryPostProcessors(PostProcessorRegistrationDelegate.java:363) ~[spring-context-6.2.8.jar:6.2.8]        at org.springframework.context.support.PostProcessorRegistrationDelegate.invokeBeanFactoryPostProcessors(PostProcessorRegistrationDelegate.java:197) ~[spring-context-6.2.8.jar:6.2.8]\n\n问题原因造成这种原因主要是因为在引入mybatisplus的时候的版本不对，我使用的springboot版本是3.4.7的，但是引入的mybatisplus的依赖版本只能适用于springboot2.x。\n解决方法在pom文件中修改mybatisplus的版本以适配当前springboot版本。下方是mybatis—plus和springboot对应的版本关系。\n\n\n\nSpring Boot\nJDK\n推荐 MyBatis-Plus\n说明\n\n\n\n3.2.x &#x2F; 3.1.x\n17+\n3.5.5+\nJakarta 命名空间\n\n\n3.0.x\n17\n3.5.3+\n初期版本\n\n\n2.7.x\n8 &#x2F; 11\n3.5.3.2 ~ 3.5.5\n⭐ 最稳定、最常用\n\n\n2.6.x\n8 &#x2F; 11\n3.5.2 ~ 3.5.4\n可用\n\n\n2.5.x\n8\n3.4.3.4 ~ 3.5.1\n偏老\n\n\n≤ 2.4.x\n8\n≤ 3.4.x\n不建议新项目\n\n\n","categories":["错误汇总"],"tags":["Java"]},{"title":"Seata配置传递失败","url":"/2026/01/19/error/Seata%E9%85%8D%E7%BD%AE%E4%BC%A0%E9%80%92%E5%A4%B1%E8%B4%A5/","content":"问题背景微服务中有两个模块，common和cart模块，此时我想要给cart模块做分布式事务，所以要引入seata，因为考虑到可能其他模块也会用到分布式事务，所以我将该依赖直接引入到common中，依赖如下。\n&lt;!--seata--&gt;&lt;dependency&gt;    &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt;    &lt;artifactId&gt;spring-cloud-starter-alibaba-seata&lt;/artifactId&gt;&lt;/dependency&gt;\n\n引入后启动cart服务，报了如下错误。\n11:13:19:906 ERROR 20948 --- [eoutChecker_1_1] i.s.c.r.netty.NettyClientChannelManager  : can not get cluster name in registry config &#x27;service.vgroupMapping.default_tx_group&#x27;, please make sure registry config correct\n\n问题原因报错分析该处报错表明 Seata 客户端 在尝试查找default_tx_group事务组对应的集群名称，但你的配置里使用的是 hmall事务组（根据之前的配置）。但是我比对了seata服务端和客户端的所有文件均没有问题，真正问题所在如下。\n原因分析1.配置未生效在 common 模块引入了 spring-cloud-starter-alibaba-seata，但未在cart-service中显式配置 Seata 的事务组名称，导致Seata 客户端 回退到默认值 default_tx_group。2.依赖传递问题common 模块的依赖虽然传递到了cart-service，但 Seata 的配置不会自动继承，需要在每个微服务中单独配置。\n解决方法对于seata配置来说，在哪个微服务中需要使用一定要在对应的微服务中引入，然后在对应的微服务中需要加上seata的配置信息。\n","categories":["错误汇总"],"tags":["Java"]},{"title":"@NotNull失效","url":"/2026/01/19/error/@NotNull%E5%A4%B1%E6%95%88/","content":"问题背景今天将一个老项目的JDK从8升级到17以后发现所有的校验全部失效了，属性如下。\nimport javax.validation.constraints.NotNull;@NotNull(message = &quot;authType不能为空&quot;)private Integer authType;\n\n问题分析查阅资料以后发现，根本原因是 Java EE（Java Enterprise Edition）整体从 Oracle 转移到了 Eclipse 基金会，并更名为 Jakarta EE。由于 Oracle 拥有 “Java” 商标，Eclipse 基金会不能继续使用 javax.* 包名。因此，从 Jakarta EE 9 开始（2020年发布），所有原 Java EE 的 API 从 javax.* 重命名为 jakarta.*。这种问题最容易出现在升级了JDK17以后。\n解决方法修改导包路径即可，其他的校验注解的路径也一样。\nimport jakarta.validation.constraints.NotNull;","categories":["错误汇总"],"tags":["Java"]},{"title":"IDEA中快捷注释键不自动缩进","url":"/2026/01/19/idea-config/IDEA%E4%B8%AD%E5%BF%AB%E6%8D%B7%E6%B3%A8%E9%87%8A%E9%94%AE%E4%B8%8D%E8%87%AA%E5%8A%A8%E7%BC%A9%E8%BF%9B/","content":"问题背景在使用ctrl + &#x2F;快速注释以后，注释会显示在最左侧，看起来非常不舒服如下图。\n解决步骤修改Java中的注释修改完成以后的结果如下\n修改XML中的注释\n其他语言的注释格式也是同样的修改方式，可以自行尝试修改。\n未解决问题每次我在空白行处进行快速注释的时候，目前IDEA会根据下一行的列数来自定判定注释的位置，效果如下。\n但实际上我想要的效果如下，目前还有没找到修改方法，如果有大佬知道怎样修改请不吝赐教。\n","categories":["IDEA配置"],"tags":["IDEA","配置"]},{"title":"前端接收大数字有误","url":"/2026/01/19/error/%E5%89%8D%E7%AB%AF%E6%8E%A5%E5%8F%97%E5%A4%A7%E6%95%B0%E5%AD%97%E6%9C%89%E8%AF%AF/","content":"问题背景后端返回给前端的json对象中的id:1985693289158844418。但是前端收到的结果是id:1985693289158844420。该id的类型是Long类型的。\n问题原因JavaScript 的 Number 类型是基于 IEEE 754 双精度浮点数（64 位）实现的，其安全整数范围是 -(2^53 - 1) 到 2^53 - 1（即 ±9007199254740991）。超出这个范围的整数无法被精确表示。\n解决方法因为我们不可以手动将id的类型从Long类型改成String类型，这样会导致大量代码需要修改。使用 @JsonFormat(shape = JsonFormat.Shape.STRING)（Jackson）如下所示，这样id返回给前端的时候就是以字符串的形式发送了。\n@JsonFormat(shape = JsonFormat.Shape.STRING)private Long id;","categories":["错误汇总"],"tags":["Java"]},{"title":"mapstruct映射失败","url":"/2026/01/19/error/mapstruct%E6%98%A0%E5%B0%84%E5%A4%B1%E8%B4%A5/","content":"问题背景目前有两个类分别为UserVO和User类他们都继承了BaseObject，我在使用mapStruct的时候发现，User中的属性都成功赋值到了UserVO中，但是User中的BaseObject中的属性没有赋值到UserVO的BaseObject中。\n问题原因检查很久发现是因为在User中，我使用了@Builder的原因，当mapStruct在创建实现类的时候发现User类中有@Builder注解默认情况下就会通过建造者模式来构建对象，这就导致了BaseObject中的属性没有被赋值。这个是@Builder的问题导致的。当然如果在User中如果没有使用@Builder的话，mapStruct在构建实现类的时候就会通过get和set的最传统的方式生成。\n解决方法一般情况下我们的代码中也会用到@Builder，所以给出解决方法如下。这个属性表示让该接口的实现类中在需要构建类的时候默认不使用建造者模式。\nbuilder = @org.mapstruct.Builder(disableBuilder = true)","categories":["错误汇总"],"tags":["Java"]},{"title":"IDEA中快速创建自定义注释","url":"/2026/01/19/idea-config/IDEA%E4%B8%AD%E5%BF%AB%E9%80%9F%E5%88%9B%E5%BB%BA%E8%87%AA%E5%AE%9A%E4%B9%89%E6%B3%A8%E9%87%8A/","content":"问题背景在创建实体类或者方法以后，想要快速给其添加注释，如果手动输入的话会很慢，此时需要一组快捷键能快速生成注释代码块。\n操作步骤配置基本信息首先，按照下图顺序来配置基本信息。\n配置模板的作用范围默认情况下，设置完上述操作后是不生效的，需要配置该模板的生效的语言范围，比如说想让改模板只在Java中生效，那么在下图中只勾选Java即可，如果想偷懒就直接选择Everywhere。\n配置函数表达式因为我们在设置模板的时候使用到模板变量$DATE$，我们需要配置该变量，目的是当我们通过快捷键打印出改段注释的时候可以直接获取当前的日期。配置方法如下。\n至此，改配置已经完成，下面贴出两个我的常用的模板。\n类注释，快捷键：mas/** * $description$ * * @author  EnyooXu * @date    $DATE$ */\n\n方法注释，快捷键：md/** * $description$ * * @param  $param$ * @return 响应结果 */","categories":["IDEA配置"],"tags":["IDEA","配置","注释"]},{"title":"Redis","url":"/2026/01/21/study/Redis/","content":"简介Redis（REmote DIctionary Server），是一个开源的、高性能的内存数据库&#x2F;缓存&#x2F;消息中间件。\n数据类型String简介在 Redis 的所有数据结构中，String（字符串） 是最基础、最底层，也是使用频率最高的一种。虽然它叫“String”，但它不仅能存储文本，还能存储整数、浮点数、甚至二进制数据（如图片或序列化后的对象）。\n常用命令\n\n\n命令\n功能\n示例\n说明\n\n\n\nSET key value [NX&#x2F;XX] [EX seconds] [PX milliseconds]\n设置 key 的值，可带条件或过期时间\nSET mykey &quot;Hello&quot; EX 10 NX\n将 mykey 设置为 &quot;Hello&quot;，10 秒后过期，仅当 key 不存在时设置；NX&#x3D;仅不存在时设置，XX&#x3D;仅存在时设置，EX&#x3D;秒过期，PX&#x3D;毫秒过期\n\n\nGET key\n获取 key 的值\nGET mykey\n获取 mykey 的值，返回 &quot;Hello&quot;\n\n\nGETSET key value\n设置新值并返回旧值\nGETSET mykey &quot;World&quot;\n将 mykey 的值改为 &quot;World&quot;，返回旧值 &quot;Hello&quot;\n\n\nMGET key1 key2 …\n获取多个 key 的值\nMGET mykey anotherkey\n返回多个 key 的值，例如 [&quot;World&quot;, &quot;value2&quot;]\n\n\nSETNX key value\n当 key 不存在时设置值\nSETNX mykey &quot;Hello&quot;\n仅当 mykey 不存在时才设置值，存在则不做修改，返回 1 成功，0 失败\n\n\nSETEX key seconds value\n设置值并指定过期时间（秒）\nSETEX mykey 10 &quot;Hello&quot;\n设置 mykey 为 &quot;Hello&quot; 并在 10 秒后过期\n\n\n应用\n缓存 (Caching)这是最普遍的用法。将复杂的数据库查询结果（通常序列化为 JSON 字符串）存入 Redis，并设置过期时间。\n\nSET user:1001 &#x27;&#123;&quot;name&quot;:&quot;张三&quot;, &quot;age&quot;:25&#125;&#x27; EX 3600\n\n\n计数器 (Counter)利用其原子性。例如：文章阅读量、微博转发数、视频点赞数。例如：有一个需求希望id能一直递增，例如1,2,3,4,5，当删除了id为5的数据后，希望下一次增加数据的id为6，这种情况下非常推荐使用该计数器。\n\nINCR post:view:45672\n\n\n分布式锁 (Distributed Lock)利用 SET … NX 特性。\n\nSET lock_order_123 &quot;process_id&quot; NX EX 10\n\n\n限速器 (Rate Limiter)例如限制某个 IP 每分钟只能访问 10 次，防止恶意刷接口。\n\n# 伪代码逻辑val = INCR ip:192.168.1.1IF val == 1 THEN EXPIRE ip:192.168.1.1 60IF val &gt; 10 THEN REJECT\n\nHash简介Hash（哈希） 是一个 String 类型的 Field（字段） 和 Value（值） 的映射表。 如果你熟悉编程语言，可以把它类比为 Python 的dict、Java的 HashMap 或者 PHP 的 Array。上文中String类型存的都是一个类型的数据，Hash可以理解为存的是一个JSON对象。redis可以直接操作这个JSON对象。\n常用命令\n\n\n命令\n功能\n示例\n说明\n\n\n\nHSET key field value\n设置哈希字段的值\nHSET user:1 name &quot;Alice&quot;\n将 user:1 的 name 字段设置为 &quot;Alice&quot;\n\n\nHGET key field\n获取哈希字段的值\nHGET user:1 name\n获取 user:1 的 name 字段值，返回 &quot;Alice&quot;\n\n\nHMSET key field1 value1 field2 value2 …\n设置多个哈希字段的值\nHMSET user:1 age 25 city &quot;New York&quot;\n同时设置多个字段，例如 age 为 25，city 为 &quot;New York&quot;\n\n\nHMGET key field1 field2 …\n获取多个哈希字段的值\nHMGET user:1 name age\n获取多个字段的值，返回 [&quot;Alice&quot;, &quot;25&quot;]\n\n\nHGETALL key\n获取哈希中所有字段和值\nHGETALL user:1\n获取整个哈希，返回 [&quot;name&quot;, &quot;Alice&quot;, &quot;age&quot;, &quot;25&quot;, &quot;city&quot;, &quot;New York&quot;]\n\n\nHDEL key field1 field2 …\n删除一个或多个哈希字段\nHDEL user:1 age city\n删除指定字段，例如 age 和 city\n\n\nHEXISTS key field\n判断哈希字段是否存在\nHEXISTS user:1 name\n如果字段存在返回 1，否则返回 0\n\n\nHKEYS key\n获取哈希中所有字段\nHKEYS user:1\n返回哈希中所有字段名，例如 [&quot;name&quot;]\n\n\nHVALS key\n获取哈希中所有值\nHVALS user:1\n返回哈希中所有字段值，例如 [&quot;Alice&quot;]\n\n\nHLEN key\n获取哈希字段数量\nHLEN user:1\n返回field数量\n\n\n应用\n存储对象数据如购物车信息（Key 为用户 ID，Field 为商品 ID，Value 为商品数量、用户信息、配置信息。\n聚合数据统计比如统计一篇文章的多个指标（阅读数、点赞数、收藏数），可以全部放在一个 Hash Key 下，方便统一管理。\n\n存储原理Hash数据类型的底层存储并不是一成不变的，而是会根据数据规模和配置在ziplist / listpack 和 hashtable两种编码之间自动切换，这是Redis 非常经典的一种“节省内存的设计”。\n\nziplist &#x2F; listpack：当Hash中的字段数量较少，每个 field 和 value 的长度较短时会使用该种结构，这种结构本质就是一块连续的内存，没有指针，非常节省内存。在Redis3.x ~ 5.x会使用 ziplist，在Redis 6.0+：改为 listpack（ziplist 的升级版）。\nhashtable：当Hash中字段大于512或者任一 field 或 value 长度 &gt; 64 字节时就会转成hashtable结构，他的底层是Redis 自己实现的dict，基于数组 + 链表的结构，查询速度基本为o(1)，但是同时有指针带来的开销，会增加内存的使用空间。\n\nList简介Redis 的 List 是一个“有序、可重复、两端高效操作”的链表结构，底层从 ziplist&#x2F;listpack 进化为quicklist。可以将它理解为Java中的Deque这种数据结构。\n常用命令\n\n\n命令\n功能\n示例\n说明\n\n\n\nLPUSH key value1 value2 …\n将一个或多个值插入列表头部\nLPUSH mylist a b c\n按顺序插入头部，最终列表为 [&quot;c&quot;,&quot;b&quot;,&quot;a&quot;]\n\n\nRPUSH key value1 value2 …\n将一个或多个值插入列表尾部\nRPUSH mylist a b c\n按顺序插入尾部，最终列表为 [&quot;a&quot;,&quot;b&quot;,&quot;c&quot;]\n\n\nLPOP key\n移除并获取列表的第一个元素\nLPOP mylist\n移除并返回列表头部的元素\n\n\nRPOP key\n移除并获取列表的最后一个元素\nRPOP mylist\n移除并返回列表尾部的元素\n\n\nLLEN key\n获取列表长度\nLLEN mylist\n返回列表中元素的数量\n\n\nLRANGE key start end\n获取列表中指定范围的元素\nLRANGE mylist 0 -1\n获取整个列表，返回 [&quot;c&quot;,&quot;b&quot;,&quot;a&quot;]\n\n\nLLEN key\n获取列表的长度\nLLEN mylist\n返回 3（列表中元素个数）\n\n\nLINDEX key index\n根据下标获取列表中的元素\nLINDEX mylist 1\n返回 &quot;b&quot;（索引从 0 开始）\n\n\nLSET key index value\n修改列表指定下标位置的值\nLSET mylist 1 &quot;x&quot;\n将索引 1 的元素修改为 &quot;x&quot;，列表变为 [&quot;c&quot;,&quot;x&quot;,&quot;a&quot;]\n\n\nLTRIM key start end\n按指定区间裁剪列表\nLTRIM mylist 0 1\n只保留索引 0 和 1 的元素，列表变为 [&quot;c&quot;,&quot;x&quot;]\n\n\n应用\n消息队列 &#x2F; 任务队列生产者将任务LPUSH到列表头部，消费者用RPOP或BRPOP弹出执行。一般在异步任务处理、日志收集、消息通知等方面可以使用。\n\nLPUSH task_queue &quot;task1&quot;LPUSH task_queue &quot;task2&quot;RPOP task_queue\n\n\n最近访问 &#x2F; 历史记录使用列表头部插入新元素，限制长度 LTRIM。适用于浏览历史、聊天记录、操作日志。只保留最新的 N 条数据。\n\nLPUSH user:123:recent_views &quot;item42&quot;LTRIM user:123:recent_views 0 9  # 只保留最近10条LRANGE user:123:recent_views 0 -1\n\nSet简介Set 是一种 无序、不重复元素集合，可以把它想象成数学中的集合，操作元素很高效，并且可以快速做集合运算。\n常用命令\n\n\n命令\n功能说明\n示例\n效果说明\n\n\n\nSADD key member [member …]\n添加一个或多个元素到集合\nSADD myset a b c\n集合 myset 中增加元素 a、b、c，重复元素会被忽略\n\n\nSREM key member [member …]\n从集合中删除一个或多个元素\nSREM myset b\n删除集合 myset 中的元素 b\n\n\nSISMEMBER key member\n判断元素是否在集合中\nSISMEMBER myset a\n返回 1 表示元素 a 存在，0 表示不存在\n\n\nSCARD key\n获取集合元素数量\nSCARD myset\n返回集合 myset 的元素个数\n\n\nSMEMBERS key\n获取集合中的所有元素\nSMEMBERS myset\n返回集合 myset 的所有元素，如 [&quot;a&quot;,&quot;c&quot;]\n\n\nSRANDMEMBER key [count]\n随机返回一个或多个元素\nSRANDMEMBER myset 2\n随机返回集合中的 2 个元素，不删除\n\n\nSPOP key [count]\n随机弹出一个或多个元素\nSPOP myset 1\n随机弹出集合中 1 个元素，元素会被删除\n\n\nSMOVE source dest member\n将元素从一个集合移动到另一个集合\nSMOVE myset otherset a\n将元素 a 从 myset 移到 otherset\n\n\nSINTER key [key …]\n求多个集合的交集\nSINTER set1 set2\n返回集合 set1 和 set2 的公共元素\n\n\nSUNION key [key …]\n求多个集合的并集\nSUNION set1 set2\n返回集合 set1 和 set2 的所有元素去重\n\n\nSDIFF key [key …]\n求集合差集\nSDIFF set1 set2\n返回在 set1 但不在 set2 的元素\n\n\nSINTERSTORE dest key [key …]\n求交集并存入新集合\nSINTERSTORE newset set1 set2\n将 set1 与 set2 的交集存入 newset\n\n\nSUNIONSTORE dest key [key …]\n求并集并存入新集合\nSUNIONSTORE newset set1 set2\n将 set1 与 set2 的并集存入 newset\n\n\nSDIFFSTORE dest key [key …]\n求差集并存入新集合\nSDIFFSTORE newset set1 set2\n将 set1 与 set2 的差集存入 newset\n\n\n应用\n存储的值需要唯一因为set自动会进行去重，所以可以用来做存储唯一的用户 ID、IP、手机号等。\n\nSADD user_ids 123SADD user_ids 123  # 不会重复\n\n\n用来做社交关系比如说用set来存储用户关注，当需要查询共同好友，互粉等情况时，可以使用set来实现。\n\nSINTER user:alice:friends user:bob:friends\n\n\n抽奖的实现因为set是无序的，所以每次从set中抽出的值都是随机的，可以用来模拟抽奖。\n\nSRANDMEMBER prizes 3\n\n存储原理set底层是有两种数据结构的分别是intset和hashtable，底层小集合用 intset 压缩存储，大集合用哈希表，高效支持查找、添加、删除和集合运算，同时自动根据元素类型和数量切换存储策略。\n\n当集合元素全是整数且数量较少时会使用intset，他是一块连续的内存数组，占用内存较小，查询效率极高。\n当添加非整数或者元素数量超阈值（默认512），Redis 会自动转换为 Hash Table。底层使用dict（哈希表）存储，只使用哈希表的key，value通常默认都是为null来保证元素的唯一性，查找、添加、删除都非常快，但是他会占用更多的内存空间。\n\nZSet简介ZSet是一种 有序、唯一元素集合，其中每一个元素都有一个分数，并按照元素按照分数升序排序，分数可以相同，但是元素不可以重复。\n常用命令\n\n\n命令\n功能说明\n示例\n效果说明\n\n\n\n\n\nZADD key score member [score member …]\n添加一个或多个元素到有序集合，若元素存在则更新 score\nZADD myzset 1 a 2 b\n将元素 a（score&#x3D;1）和 b（score&#x3D;2）添加到 myzset，如果已存在则更新分数\n\n\n\n\nZREM key member [member …]\n从有序集合中删除一个或多个元素\nZREM myzset a\n删除 myzset 中的元素 a\n\n\n\n\nZSCORE key member\n获取元素的 score 值\nZSCORE myzset a\n返回元素 a 的 score 值，例如 1.0\n\n\n\n\nZRANK key member\n获取元素按 score 升序的排名\nZRANK myzset b\n返回元素 b 的排名（0 为最小 score），不存在返回 nil\n\n\n\n\nZREVRANK key member\n获取元素按 score 降序的排名\nZREVRANK myzset b\n返回元素 b 的降序排名\n\n\n\n\nZRANGE key start stop [WITHSCORES]\n按排名范围返回元素，可选返回 score\nZRANGE myzset 0 1 WITHSCORES\n返回排名第 0 和 1 的元素及 score，例如 [(&quot;a&quot;,1),(&quot;b&quot;,2)]\n\n\n\n\nZREVRANGE key start stop [WITHSCORES]\n按排名逆序返回元素，可选返回 score\nZREVRANGE myzset 0 1 WITHSCORES\n返回最高 score 前两个元素及 score\n\n\n\n\nZRANGEBYSCORE key min max [WITHSCORES]\n按 score 范围返回元素\nZRANGEBYSCORE myzset 1 2 WITHSCORES\n返回 score 在 1~2 范围的元素及 score\n\n\n\n\nZREVRANGEBYSCORE key max min [WITHSCORES]\n按 score 范围逆序返回元素\nZREVRANGEBYSCORE myzset 2 1 WITHSCORES\n返回 score 在 2~1 范围的元素及 score（降序）\n\n\n\n\nZCOUNT key min max\n统计 score 在指定范围的元素数量\nZCOUNT myzset 1 2\n返回 score 在 1~2 的元素数量\n\n\n\n\nZCARD key\n获取有序集合中元素数量\nZCARD myzset\n返回 myzset 中元素总数\n\n\n\n\nZINCRBY key increment member\n给元素的 score 增加指定值\nZINCRBY myzset 2 a\n元素 a 的 score 增加 2，如果不存在则添加 a 并设置 score&#x3D;2\n\n\n\n\nZPOPMIN key [count]\n弹出 score 最小的元素，可指定数量\nZPOPMIN myzset 1\n返回并删除 score 最小的元素\n\n\n\n\nZPOPMAX key [count]\n弹出 score 最大的元素，可指定数量\nZPOPMAX myzset 1\n返回并删除 score 最大的元素\n\n\n\n\nZREM RANGE BY RANK key start stop\n按排名范围删除元素\nZREMRANGEBYRANK myzset 0 1\n删除排名第 0 和 1 的元素\n\n\n\n\nZREM RANGE BY SCORE key min max\n按 score 范围删除元素\nZREMRANGEBYSCORE myzset 1 2\n删除 score 在 1~2 范围的元素\n\n\n\n\n应用\n排行榜 &#x2F; 积分榜可以拿key当做用户id，value来存储用户的游戏积分，并按照积分来进行排序。其他排行榜也是类似使用。\n带去重的延迟队列一般情况下使用list就可以完成延迟队列，但是如果需要实现去重就可以使用zset数据结构。\n\nGEO用于存储地理坐标（经度、纬度）并支持各种地理空间的计算如： 距离计算、 范围搜索、 最近点查询、 按距离排序；\n常用命令\n\n\n命令\n功能说明\n示例\n执行效果\n\n\n\nGEOADD key longitude latitude member [longitude latitude member ...]\n添加地理位置坐标到指定 key\nGEOADD locations 116.397128 39.916527 &quot;Beijing&quot;\n将 &quot;Beijing&quot; 的经纬度坐标加入 locations\n\n\nGEOPOS key member [member ...]\n获取一个或多个成员的经纬度\nGEOPOS locations &quot;Beijing&quot;\n返回 [116.397128, 39.916527]\n\n\nGEODIST key member1 member2 [unit]\n计算两个成员之间的距离\nGEODIST locations &quot;Beijing&quot; &quot;Shanghai&quot; km\n返回北京到上海的距离（单位 km）\n\n\nGEOHASH key member [member ...]\n返回成员的 geohash 值\nGEOHASH locations &quot;Beijing&quot;\n返回 &quot;wx4g0c0&quot; 形式的 geohash 编码\n\n\n应用\n附近的人 &#x2F; 商家 &#x2F; 车辆比如说打车软件中的“查找用户周围 1km内的出租车”等。注意着点和neo4j的功能不同，neo4j更加侧重于最优路径的计算。以物流运输成本为例：因为在一个实际运输项目中还有包含运费过路费等其他复杂情况，有时候不一定距离最短的情况下成本是最低的，neo4j更擅长这种计算。\n\n除了上述的这些数据结构以外，redis还有很多其他类型的数据结构，但是使用频率一般情况下来说不是很高，有需要可以再了解。\n通用指令\n\n\n命令\n功能说明\n示例\n效果说明\n\n\n\nDEL key [key …]\n删除一个或多个键\nDEL mykey\n删除键 mykey，如果不存在则忽略\n\n\nEXISTS key [key …]\n判断一个或多个键是否存在\nEXISTS mykey\n返回 1 表示存在，0 表示不存在\n\n\nEXPIRE key seconds\n设置键的过期时间（秒）\nEXPIRE mykey 60\nmykey 在 60 秒后自动删除\n\n\nPEXPIRE key milliseconds\n设置键的过期时间（毫秒）\nPEXPIRE mykey 1500\nmykey 在 1.5 秒后自动删除\n\n\nTTL key\n查看键的剩余生存时间（秒）\nTTL mykey\n返回 mykey 的剩余生存时间，-1 表示永久，-2 表示不存在\n\n\nPTTL key\n查看键的剩余生存时间（毫秒）\nPTTL mykey\n返回 mykey 的剩余毫秒数\n\n\nPERSIST key\n移除键的过期时间，使其永久存在\nPERSIST mykey\nmykey 成为永久键，不再过期\n\n\nRENAME key newkey\n重命名键\nRENAME mykey newkey\n将 mykey 重命名为 newkey，如果 newkey 存在会覆盖\n\n\nRENAMENX key newkey\n仅当 newkey 不存在时重命名\nRENAMENX mykey newkey\n返回 1 表示成功重命名，0 表示 newkey 已存在\n\n\nTYPE key\n查看键的数据类型\nTYPE mykey\n返回 mykey 的类型，如 string、list、set、zset、hash\n\n\nKEYS pattern\n查找符合模式的键\nKEYS user*\n返回所有以 user 开头的键（不推荐生产环境大量使用）\n\n\nSCAN cursor [MATCH pattern] [COUNT count]\n增量迭代扫描键\nSCAN 0 MATCH user* COUNT 10\n返回部分符合模式的键，支持分页迭代，安全生产使用\n\n\nTTL key\n获取键的剩余时间（秒）\nTTL mykey\n查看 mykey 剩余秒数，-1 表示永久，-2 表示不存在\n\n\nDUMP key\n序列化键的值为二进制字符串\nDUMP mykey\n返回 mykey 的序列化二进制，可以用于迁移或备份\n\n\nRESTORE key ttl serialized-value\n恢复序列化的键值\nRESTORE mykey 0 &quot;\\x00...&quot;\n将序列化数据恢复成键 mykey\n\n\nEXISTS key\n判断键是否存在\nEXISTS mykey\n返回 1 表示存在，0 表示不存在\n\n\nOBJECT subcommand key\n查看键的内部信息\nOBJECT REFCOUNT mykey\n查看键的引用计数、编码方式等（调试用）\n\n\nMOVE key db\n将键移动到指定数据库\nMOVE mykey 1\n将 mykey 移到 Redis 的 db1，如果目标 db 有同名键返回 0\n\n\nFLUSHDB\n删除当前数据库的所有键\nFLUSHDB\n当前数据库全部清空\n\n\nFLUSHALL\n删除所有数据库的所有键\nFLUSHALL\nRedis 实例中所有键全部清空\n\n\nPERSIST key\n移除键的过期时间\nPERSIST mykey\n使 mykey 永久存在\n\n\nRENAME key newkey\n重命名键\nRENAME mykey newkey\n将 mykey 改名为 newkey\n\n\nRedis问题缓存雪崩简介缓存雪崩（Cache Avalanche）是指在极短时间内，大量的缓存同时失效，或者 Redis 插件宕机，导致原本应该访问缓存的请求全部涌向数据库，造成数据库压力剧增甚至崩溃的现象。\n解决方法大量 Key 同时过期这是最常见的雪崩诱因，通常是因为批量写入数据时设置了相同的过期时间。\n\n设置随机过期时间： 在原有的过期时间基础上，加上一个随机值（例如 1-5 分钟的随机偏差）。这样可以分散 Key 的失效时间点，避免集体过期。\n设置热点数据永不过期： 对于一些极高频访问的业务数据，不设置过期时间，而是由后台逻辑在数据更新时主动去同步或更新缓存。\n逻辑过期： 在缓存的 Value 中包含一个“过期时间”字段。查询时发现逻辑时间已过期，则通过中间件或异步线程去更新缓存，而当前请求先返回旧数据，实现“准实时”且“高可用”。\n\nRedis 宕机&#x2F;不可用如果雪崩是因为 Redis 服务本身挂了，就需要在架构层面进行加固。\n\n构建 Redis 高可用集群： 使用 Redis Sentinel（哨兵模式） 或 Redis Cluster（集群模式）。当主节点宕机时，系统能自动进行故障转移，实现秒级切换。\n多级缓存架构： 使用 本地缓存（如 Guava Cache、Caffeine） + 远程分布式缓存（Redis）。 即使 Redis 挂了，本地缓存还能扛住一部分流量，为数据库争取缓冲时间。\n\n数据库层级的保护当缓存已经失效，流量已经冲向数据库时，就需要在数据库层最后一层防线。\n\n服务熔断与限流： 使用 Sentinel 或 Hystrix 等组件。一旦检测到数据库压力过大或响应变慢，直接启动熔断机制，暂停非核心业务的访问，并进行请求降级（返回默认值或错误页面），保护数据库不被冲垮。\n\n缓存击穿简介缓存击穿是指某一个极其热点的 Key 在过期的瞬间，有海量的并发请求同时涌入。由于缓存失效，这些请求会同时冲向数据库，可能导致数据库瞬间瘫痪。\n解决方法互斥锁(redis分布式锁)这是最常用的方案。当缓存失效时，不立即去查询数据库，而是先尝试获取一个互斥锁（如 Redis 的setnx），只有获得锁的那个线程能去查询数据库并回写缓存，其他线程则不断重试或等待。这样当获得锁的线程查询数据库以后会将值重新放到缓存中，并将锁释放。当其他线程发现获取锁后会第一时间再次查询redis中的数据，发现此时已经有数据了就直接返回，没有的话重复第一个线程的动作。这种方法通常用在订单，金融方面等对数据的准确性要求较高的地方使用。下面举一个使用Redisson实现分布式锁的例子。\nimport org.redisson.api.RLock;import org.redisson.api.RedissonClient;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.data.redis.core.StringRedisTemplate;import org.springframework.stereotype.Service;import java.util.concurrent.TimeUnit;@Servicepublic class CacheService &#123;    @Autowired    private StringRedisTemplate redisTemplate;    @Autowired    private RedissonClient redissonClient;    public String getData(String key) &#123;        // 1. 先从缓存中获取数据        String value = redisTemplate.opsForValue().get(key);        // 2. 缓存命中则直接返回        if (value != null) &#123;            return value;        &#125;        // 3. 缓存缺失，准备获取互斥锁        String lockKey = &quot;lock:&quot; + key;        RLock lock = redissonClient.getLock(lockKey);        try &#123;            /*             * tryLock 参数说明：             * waitTime:  等待锁的时间（10秒），超过则放弃             * leaseTime: 锁的自动释放时间（30秒），防止宕机死锁             */            if (lock.tryLock(10, 30, TimeUnit.SECONDS)) &#123;                try &#123;                    // 4. 【关键】获取锁后，再次检查缓存（Double Check）                    // 理由：高并发下，第一个线程写完缓存释放锁后，后续线程进锁时不应再查库                    value = redisTemplate.opsForValue().get(key);                    if (value != null) &#123;                        return value;                    &#125;                    // 5. 查询数据库                    value = queryDatabase(key);                    // 6. 回写缓存，并设置随机过期时间防止雪崩                    if (value != null) &#123;                        int expireTime = 30 + (int) (Math.random() * 10); // 30-40min                        redisTemplate.opsForValue().set(key, value, expireTime, TimeUnit.MINUTES);                    &#125;                &#125; finally &#123;                    // 7. 释放锁                    lock.unlock();                &#125;            &#125; else &#123;                // 8. 获取不到锁的线程，休眠后重试（或返回降级结果）                Thread.sleep(100);                return getData(key);            &#125;        &#125; catch (InterruptedException e) &#123;            Thread.currentThread().interrupt();            return null; // 或者抛出业务异常        &#125;        return value;    &#125;    private String queryDatabase(String key) &#123;        // 模拟数据库查询        return &quot;DataFromDB_for_&quot; + key;    &#125;&#125;\n\n逻辑过期这种方案不再给 Redis 的 Key 设置真实的过期时间（TTL），而是把过期时间存放在 Value 字段中。\n\n查询缓存，取出数据后判断其中的“逻辑过期时间”。\n如果已过期，开启一个异步线程去查询数据库并更新缓存。\n在异步更新完成前，当前请求（以及其他并发请求）直接返回旧数据。\n\n这种做法的性能极高，不存在线程阻塞等待，用户体验好，但是会存在数据不一致的情况（用户会拿到旧数据），且会增加代码的复杂度。\n其他方法\n热点数据预热： 在秒杀活动或高峰期开始前，提前将热点 Key 写入缓存，并手动延长其有效期。\n永久不过期： 对于流量极大的静态配置类数据，直接设置为永久有效，通过后台管理系统手动触发更新。\n\n\n缓存穿透简介缓存穿透指查询一个根本不存在的数据。由于缓存中没有（肯定没中），数据库中也没有（查询结果为空），导致每次请求都要去数据库查询。如果有攻击者伪造大量不存在的Key 进行恶意攻击，数据库会因承受不住压力而瘫痪。\n解决方法缓存空对象当数据库返回空结果时，我们也把这个“空值”（如 null 或特定的默认值）写入缓存，并设置一个较短的过期时间（例如 1-5分钟）。这种方法实现简单且维护方便，但是如果查询redis中的key是随机生成的会消耗Redis大量内存来存储这些空数据。通过可能会导致短期的数据不一致(如果之后数据库真的插入了这个 Key 的数据)。\n布隆过滤器在请求进入缓存层之前，先经过一层布隆过滤器。布隆过滤器由一个很长的二进制向量（位图）和一系列哈希函数组成。它能告诉你：“这个Key 可能存在”或“这个 Key 绝对不存在”。 如果布隆过滤器说不存在，直接拦截请求并返回。 如果布隆过滤器说可能存在，才去访问 Redis和数据库。布隆过滤器占用的内存很小而且能有效拦截大部分的非法请求，但是通过也是存在误判的可能。\n@Autowiredprivate RedissonClient redissonClient;public String getDataWithBloom(String key) &#123;    // 1. 获取布隆过滤器    RBloomFilter&lt;String&gt; bloomFilter = redissonClient.getBloomFilter(&quot;user_filter&quot;);    // 2. 如果布隆过滤器判断绝对不存在，直接拦截    if (!bloomFilter.contains(key)) &#123;        return null;    &#125;    // 3. 后续走正常的 Redis -&gt; DB 逻辑    String value = redis.get(key);    if (value == null) &#123;        value = db.query(key);        if (value == null) &#123;            // 配合“缓存空值”方案，双重保险            redis.set(key, &quot;&quot;, 60, TimeUnit.SECONDS);        &#125; else &#123;            redis.set(key, value);        &#125;    &#125;    return value;&#125;\n\n其他方法在请求接受的源头处做一定的过滤，比如说ID的长度为8，那么当请求来的时候可知直接在Controller层拦截掉，这种方法能过滤掉大部分低级的、无脑的恶意攻击。\nRedis持久化简介Redis 的持久化主要为了解决一个问题：Redis 数据存储在内存中，一旦服务器宕机或重启，内存中的数据就会丢失。\n持久化方式RDB工作原理RDB的核心思想是定时拍快照：在指定的时间间隔内，将内存中当前时刻的全量数据生成一个二进制文件（通常命名为dump.rdb）保存到磁盘上。在生产环境中，Redis 几乎总是使用bgsave命令来进行异步持久化，其过程如下：\n\n执行命令：主进程接收到持久化请求（手动或自动触发）。\n创建子进程：主进程调用系统的 fork() 函数创建一个子进程。\n写快照：子进程将当前内存中的数据写入一个临时的 RDB 文件。\n替换原文件：写入完成后，用临时文件替换旧的 dump.rdb 文件。\n\n写时复制：在子进程写快照期间，主进程仍然可以处理写请求。如果主进程修改了某块内存数据，操作系统会为这块数据创建一个副本，主进程在副本上修改，而子进程继续读取原始内存数据进行备份。这样既保证了数据一致性，又不阻塞主进程。\n优缺点优点：\n\n恢复速度极快：RDB 文件是压缩后的紧凑二进制数据，加载速度远快于AOF。\n性能最大化：持久化由子进程处理，主进程不需要进行任何磁盘 IO 操作。\n适合冷备：可以通过备份 dump.rdb 文件（如每天备份一次到云存储），实现异地备份。\n\n缺点：\n\n数据安全性低：RDB的致命伤。因为是间隔触发，如果 Redis 在两次快照之间崩溃，这期间的数据会全部丢失。\n资源损耗：如果内存数据量极大（比如 10GB 以上），fork 子进程的过程可能导致服务器出现明显的秒级停顿。\n\nAOF工作原理AOF 的核心思想是Redis 会将每一个写命令（如 SET、DEL、SADD 等）通过 write 函数追加到 AOF 文件的末尾。当 Redis重启时，会通过重新执行这些命令来在内存中重建整个数据集。AOF 持久化并不是直接写磁盘，而是经过了几个步骤：\n\n命令追加：写命令被追加到服务器系统的 AOF 缓冲区（aof_buf）。\n文件写入与同步：根据设置的策略，将缓冲区内容写入磁盘。\n文件重写：随着文件变大，定期压缩 AOF 文件。\n\n保存策略\n\n\n策略名称\n原理说明\n优点\n缺点\n\n\n\nAlways\n每个写命令执行完，立即同步将日志写回磁盘\n数据最安全，理论上不丢数据\n性能极差，磁盘 IO 开销巨大\n\n\nEverysec\n每个写命令执行完先写入缓冲区，每隔 1 秒将缓冲区内容同步到磁盘\n性能与安全平衡（推荐）\n宕机时可能丢失 1 秒的数据\n\n\nNo\n写命令写入缓冲区后，由操作系统决定何时同步到磁盘\n性能最好\n宕机时丢失数据量不可控\n\n\n重写机制\n由于 AOF 是追加写，文件会越来越大（例如你对一个 Key 执行了 100 次 INCR，AOF 会记录 100 条命令）。为了解决这个问题，Redis 引入了重写机制。Redis 并不需要读取旧的 AOF 文件，而是直接读取内存中的当前数据。它会生成能达到当前数据状态的最少命令。 比如：内存中count 的值是 100。重写前 AOF 有 100 条 INCR；重写后，新 AOF 只有一条 SET count 100。\n触发重写机制的条件：比上次重写后的大小翻倍时且文件至少要达到 64MB。例如：上一次AOF后的文件大小为50M，那么下一次触发重写的时机为50M * 2 &#x3D; 100M的时候才会触发。\n\n优缺点优点：\n\n数据更可靠：默认的 everysec 策略下，最多只丢 1 秒数据。\n日志易读、可修复：AOF 记录的是原始 Redis 命令。如果由于某些原因（磁盘满等）导致末尾指令写破损，可以使用 redis-check-aof工具轻松修复。\n支持“误操作”恢复：如果你不小心执行了 FLUSHALL 命令清空了数据库，只要 AOF 还没被重写，你可以立即停止服务，删掉 AOF 末尾的那条FLUSHALL 指令，重启后数据就全回来了。\n\n缺点：\n\n文件体积大：通常比相同数据集的 RDB 文件大得多。\n恢复速度慢：重启时需要“跑一遍脚本”，如果命令千万级，恢复时间会很久。\n性能压力：虽然是追加写，但在高并发下，频繁的磁盘 IO 还是会比 RDB 略慢。\n\n混合模式（RDB + AOF）工作原理\n持久化过程混合持久化（RDB + AOF）是 Redis 目前最推荐的持久化方案。它的核心逻辑是：利用 RDB 的快速恢复能力，结合 AOF 的数据实时性。在混合使用模式下，AOF 文件的结构会发生变化：它的前半部分是 二进制的 RDB 格式，后半部分是 文本格式的 AOF命令。混合持久化并不是在每一次写命令时发生的，而是在 AOF 重写（Rewrite） 的时候发生的：\n\n\n触发重写：当 AOF 文件体积达到阈值时，Redis 触发后台 AOF 重写。\n创建快照：Redis 会将当前的内存数据以 RDB 二进制 的格式写入新的 AOF 文件开头。\n记录增量：在创建快照期间，主进程收到的写命令会继续以 AOF 文本 格式追加到这个新文件的末尾。\n替换文件：重写完成后，用这个“混合型”文件替换旧的纯文本 AOF 文件。\n\n\n数据恢复当重启 Redis 服务时：\n\n\n识别格式：Redis 首先加载 AOF 文件。\n快速加载：发现开头是 RDB 格式，直接将二进制数据极速载入内存（这省去了大量命令回放的时间）。\n增量重放：加载完 RDB 部分后，继续读取并执行文件末尾的 AOF 命令，恢复重写期间的数据。\n\nRedis主从简介主从复制是 Redis 高可用的基石。它的核心思想是将一台 Redis 服务器（Master，主节点）的数据，实时同步到其他 Redis服务器（Slave&#x2F;Replica，从节点）。 在主从架构中，数据的流动是单向的：只能从主节点流向从节点。使用主从结构主要原因有以下几点：\n\n读写分离：主节点负责写操作，从节点负责读操作。由于大多数互联网场景都是“读多写少”，这能极大地提高系统的吞吐量。\n数据冗余：实现了数据的热备份，是持久化之外的另一种可靠数据保护方式。\n高可用基础：主从复制是哨兵模式和集群模式能够运行的前提。\n\n工作原理Redis 的主从同步分为两个阶段：全量复制和增量复制。\n全量复制（首次连接）当一个从节点第一次连接主节点，或者断开时间太长导致数据无法衔接时，会发生全量复制：\n\n同步请求：从节点发送 psync 命令给主节点。\n生成快照：主节点执行 bgsave 生成 RDB 文件，同时用一个缓冲区记录从现在开始的所有写命令。\n发送 RDB：主节点将 RDB 文件发送给从节点。\n加载数据：从节点清空旧数据，载入 RDB 文件。\n同步缓冲区：主节点把刚才记录在缓冲区的写命令发给从节点，从节点执行这些命令，达到数据一致。\n\n增量复制（网络闪断后）如果主从之间的网络连接断开了很短的时间，重新连接后不需要重新传整个RDB，而是只传断开期间的数据，这里首要介绍一个Offset（偏移量），可以把它想象成一个循环队列，当新的数据量到达环的尾部的时候若此时还有新的数据进来后会覆盖掉最开始的数据，主从节点都会维护一个复制偏移量（一个循环队列）。主从之间会定时发送心跳（默认1s 一次），用于检测链路状态和汇报偏移量。\n\n如果心跳中汇报的 Replica Offset &lt; Master Offset，主节点就会从复制积压缓冲区（Replication BacklogBuffer）中提取缺失的数据，重新发给从节点。\n因为Offset是一个环形数组，如果偏移量已经不在了（被覆盖了），则被迫进行全量同步。\n\n其他\n心跳检测：主从之间会定时发送心跳（默认 1s 一次），用于检测链路状态和汇报偏移量。\n异步复制：主节点处理完写命令后直接给客户端返回成功，然后异步地将命令发给从节点。这意味着主从之间存在微小的数据延迟。\n从节点只读：默认情况下，从节点是只读，这能防止数据被意外修改导致主从不一致。\n\n哨兵模式简介在简单的主从架构中，如果主节点（Master）宕机，必须人工手动将从节点（Slave）提升为主节点，并通知所有应用修改地址。而哨兵机制就是实现这一过程的自动化管家。哨兵是一个特殊的Redis 服务，它不存储数据，而是作为一个独立的进程运行，主要负责三件事：\n\n监控（Monitoring）：哨兵会不断地检查你的主服务器和从服务器是否运作正常。\n通知（Notification）：当被监视的某个 Redis 服务器出现问题时，哨兵可以通过 API 向管理员或其他应用程序发送通知。\n自动故障转移（Automatic Failover）：如果主节点挂了，哨兵会从剩下的从节点中选出一个新的主节点，并让其他从节点改为从属于新主。\n\n哨兵判断主节点是否下线：\n\n主观下线： 单个哨兵发现主节点在指定时间内没有响应（心跳检测超时），它认为这个节点“主观上”挂了。\n客观下线： 当大多数哨兵（达到配置的 quorum 数量，quorum值一般是超过Sentinel实例数量的一半）都认为该主节点已经挂了，那么这个节点就被判定为“客观下线”。此时，故障转移流程正式启动。\n\n工作原理当确认主节点“客观下线”后，哨兵们会进行如下操作：\n选举leader：Sentinel集群要选出一个执行failover的Sentinel节点，所以必须要选出由哪个sentinel来执行。要成为leader要满足两个条件：\n\n最先获得超过半数的投票（Sentinel节点的数量一般设置为奇数，最小从3开始）\n获得的投票数不小于quorum值\n\n而sentinel投票的原则有两条：\n\n优先投票给目前得票最多的\n如果目前没有任何节点的票，就投给自己\n\n例：有3个sentinel节点，s1、s2、s3，假如s2先投票：\n\n此时发现没有任何人在投票，那就投给自己。s2得1票\n接着s1和s3开始投票，发现目前s2票最多，于是也投给s2，s2得3票\ns2称为leader，开始故障转移\n\n所以，通常来说第一个确认master客观下线的人会立刻发起投票，一定会成为leader。但是有极端情况下可能会出现s1,s2,s3都投了自己怎么办，此时会宣告此轮投票失败，所有哨兵会等待一段随机的时间，然后进入下一个纪元（Epoch）重新开始选举。由于等待时间是随机的，下一轮继续按照上述规则进行投票直到选出leader。\n选取新的master新的master会从剩下的slave中选取，选取规则如下：\n\n首先会判断slave节点与master节点断开时间长短，如果超过指定值则会排除该slave节点\n然后判断slave节点的slave-priority值，越小优先级越高，如果是0则永不参与选举\n如果slave-prority一样，则判断slave节点的offset值，越大说明数据越新，优先级越高\n最后是判断slave节点的运行id大小，越小优先级越高。\n\n更换主节点此时选择出来的leader会按照下面顺序来重新执行master：\n\n选出一个 Slave，发送 SLAVE OF NO ONE 让它称为主节点。\n通知其他 Slave 连接新的master。\n发布配置更新，让所有哨兵和客户端知道主节点换人了。\n\nRedis分片集群简介当数据量突破单机物理内存限制（如超过 64GB），或者写操作并发极高单机 Master 无法抗住时，分片集群就派上用场了。如果说“哨兵”是为了高可用，那么“集群”就是为了横向扩展。分片集群采用去中心化的设计，集群中的每个节点都是平等的，彼此通过Gossip 协议 交换状态信息。此时数据不再存在一个节点上，而是分布在多个节点上。客户端可以连接集群中的任意一个节点来访问数据。\n工作原理分片集群中数据的分布机制是通过哈希槽。它没有使用简单的 hash(key) %N，因为节点增减会导致数据大规模迁移。redis中固定是有16384个哈希槽，每个物理节点负责管理一部分槽位，例：\n\n节点 A 负责：0 - 5460\n节点 B 负责：5461 - 10922\n节点 C 负责：10923 - 16383\n\n当需要查询某一个值的时候，先对key进行CRC16 校验，得到一个整数。随后将该值对 16384 取模：$slot &#x3D; CRC16(key) \\pmod{16384}$。此时得到的就是插槽的位置。当节点数增加的时候只会影响每个节点所含有的哈希槽的数量并不会影响该值的存储位置。\n集群的高可用Redis Cluster 内部包含了哨兵的功能。每个“分片”通常由一个主节点和若干个从节点组成。可以看下图更为直观。节点之间互相发送 Ping 包，如果超过半数节点认为某个 Master 挂了，该分片就会触发故障转移。此时改master下会选取一个slave称为新的master并参与到集群中。\n客户端跳转机制 (MOVED 重定向)由于数据分布在不同节点，客户端访问一个 Key 时，如果该 Key 不在当前连接的节点上就会按照下面顺序跳转：\n\n客户端发送命令给节点 A。\n节点 A 计算发现该 Key 属于节点 B 负责的槽位。\n节点 A 返回一个 MOVED 错误（包含节点 B 的 IP 和端口）。\n客户端收到后，自动重定向并连接节点 B 完成请求。\n\n为了防止二次跳转，在某些编程语言中会引入Smart Client（在启动时或运行中，通过 CLUSTER SLOTS 命令获取整个集群的槽位分布图。） 像 Java 的 Jedis 或 Lettuce 这种客户端，会在本地缓存槽位映射表（通常是一个数组，长度为 16384，其中的值为指向节点的内存地址），直接计算出应该请求哪个节点，避免二次跳转。具体流程如下：\n\n缓存路由表：客户端连接集群后，会自动拉取并维护一份本地缓存，记录：Slot 0-5460 -&gt; Node A, Slot 5461-10922 -&gt; Node B 等。\n本地计算：当你执行 SET mykey “hello” 时，客户端在发送请求前，先在本地通过 CRC16(“mykey”) % 16384 算出槽位（假设是 6000）。\n精准打击：查询本地路由表发现 6000 属于 Node B，于是直接建立连接发送给 Node B。整个过程只需一次网络 IO。\n动态更新（故障自愈）：如果集群发生了扩容、缩容或主从切换，导致槽位迁移，原有的缓存就会失效。此时客户端发送请求，Redis 节点会返回 MOVED。Smart Client 收到 MOVED 后，不仅会去请求新节点，还会自动异步更新本地路由表，确保下次请求依然精准。\n\nRedis多线程随着网络硬件的发展（比如万兆网卡），Redis 的性能瓶颈不再是 CPU 或内存，而是网络 IO 的读写。大量的时间消耗在了“从网卡读数据”和“往网卡写数据”这两个动作上。为了解决这个问题 Redis 6.0 引入了 I&#x2F;O 多线程。\n\n主线程：依然负责最重要的 “命令执行”（计算逻辑）。\nI&#x2F;O 线程：负责 “读写网络数据” 和 “协议解析”。\n\nRedis 的 数据读写逻辑（命令执行）依然是单线程的（保证了原子性和无需加锁），但网络数据的收发变成了多线程。如果命令执行变成多线程，Redis 就必须引入 “锁”（Lock）机制来保证数据安全。而加锁和释放锁都是巨大的性能开销，而且还可能会产生死锁问题，除此之外，多线程切换带来的上下文切换损耗，在内存操作这种极快的情况下，反而可能比单线程更慢。\n","categories":["学习"],"tags":["redis","中间件"]},{"title":"IDEA中文件多排显示","url":"/2026/01/19/idea-config/IDEA%E4%B8%AD%E6%96%87%E4%BB%B6%E5%A4%9A%E6%8E%92%E6%98%BE%E7%A4%BA/","content":"问题背景当IDEA中文件打开比较多的时候，会如下图所示，所有的文件都会被隐藏在更多的位置，这样在文件多的时候就不好进行切换。\n解决步骤打开文件多排显示按下图进行设置。\n设置展示文件数可以自行设置一共展示多少个页面，如下图，这个配置不设置也没有问题。\n","categories":["IDEA配置"],"tags":["IDEA","配置"]},{"title":"修改按双shift键快速全局查找","url":"/2026/01/19/idea-config/%E4%BF%AE%E6%94%B9%E6%8C%89%E5%8F%8Cshift%E9%94%AE%E5%BF%AB%E9%80%9F%E5%85%A8%E5%B1%80%E6%9F%A5%E6%89%BE/","content":"问题背景IDEA中默认情况下按两下shift会调出全局查找，但是我在写注释的时候经常需要按shift键切换，因此经常会切出全局查找，因此想修改全局查找按钮。\n操作步骤禁用双shift全局查找功能首先按下图先禁用按两次同一个修饰键触发的功能【例如双shift的全局搜索等】。\n自定义全局搜索按键禁用了双shift启动全局搜索后，我们可以自定义一个全局搜索，配置方法如下，我这里选择的是Alt + f。\n","categories":["IDEA配置"],"tags":["IDEA","配置"]},{"title":"IDEA中的Services启动多个实例的时候不显示端口号","url":"/2026/01/19/idea-config/IDEA%E4%B8%AD%E7%9A%84services%E5%90%AF%E5%8A%A8%E5%A4%9A%E4%B8%AA%E5%AE%9E%E4%BE%8B%E7%9A%84%E6%97%B6%E5%80%99%E4%B8%8D%E6%98%BE%E7%A4%BA%E7%AB%AF%E5%8F%A3%E5%8F%B7/","content":"问题背景在IDEA的Services页面启动应用的时候没有显示端口号，如下图所示。\n解决步骤删除hsperfdata文件夹进入C:\\用户\\你的用户名\\AppData\\Local\\Temp将hsperfdata_你自己用户名这个文件夹删除。也可以使用快捷方式进入Temp文件夹，快捷键win + R后在输入%temp%即可。\n重启IDEA重启IDEA以后再重启刚刚的项目即可。\n","categories":["IDEA配置"],"tags":["IDEA","配置"]},{"title":"断点怎样根据条件拦截","url":"/2026/01/19/idea-config/%E6%96%AD%E7%82%B9%E6%80%8E%E6%A0%B7%E6%A0%B9%E6%8D%AE%E6%9D%A1%E4%BB%B6%E6%8B%A6%E6%88%AA/","content":"问题背景现在有这样一个情况，当我们正在写了一部分代码后，前端提出联调，于是我们在同一个项目里面开启了两个服务如下。当我们在某一行打了断点以后，这个断点会拦截这里所有的请求，比如我正在后台请求的时候【使用8001】，此时前端同时也在请求【使用8000】，就会出现在断点处所有请求都被拦截的情况，但实际上我只想拦截这个8001的请求。\n解决步骤增加断点拦截条件我们在某一行打了断点以后，在断点上右键并按下图配置。这样在改断点处就只会拦截端口号为8001的服务了。注意这里的conditions中是可以使用live_template的，如果该字段经常要使用可以配置一下。\n","categories":["IDEA配置"],"tags":["Java","IDEA","配置","断点"]}]